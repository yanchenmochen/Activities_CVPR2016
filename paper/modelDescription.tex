\begin{figure}[tb]
\begin{center}
\fbox{\rule{0pt}{2in} \rule{0.9\linewidth}{0pt}}
%\includegraphics[width=0.99\linewidth]{./fig_graphical_hierarchic_model.pdf}
%\vspace{-1.3cm}
\end{center}
   \caption{Graphical representation of our discriminative hierarchical model for recognition of composable human activities.
At the top level, activities are represented as compositions of atomic actions that are inferred at
the intermediate level. These actions are in turn compositions of poses at the
lower level, where pose dictionaries are learned from data. Our model also learn
temporal transitions between consecutive poses and actions. Best viewed in
color.}
\label{fig:overview}
%\vspace{-0.4cm}

\end{figure}

%We build our model on top of the one presented in \cite{Lillo2014}. We improve that model in three ways: (1) adding flexibility to handle multiple types of action annotations, (2) incorporating multiple classifiers for every action instead of a single classifier, and (3) adding a \emph{garbage collector} of poses to avoid modeling noisy or non-informative poses. 

Our model for complex action recognition follows a hierarchical compositional approach based on pose and mid-level representations, such as \cite{Lillo2014} or \cite{Tao2015} .  As a distinguishing idea from previous works, we include a mechanism to infer not only the global activity label of the videos, but also recover quality temporal and spatial annotations of actions and poses. To this end, we explore three main ideas: first, we create method to automatically infer mid-level annotations for localize actions spatially. Then, going towards general action recognition, we describe a method to handle multiple classifiers for the same action, fostering to create action models with better representation power in hierarchical setups, where usually low and mid-level components are shared throughout high level activities. Finally, to complement the generalization of the model we aim to build discriminative low level classifiers. When using pose dictionaries, there is a high chance that noisy and non-informative poses are present when training low-level (pose) classifiers. In models like  \cite{Tao2015}, where  video descriptors use aggregated data of the complete video, the effect of non-informative poses is mitigated compared to a frame-based model, even when the latter provide richer interpretations. We build our model in a general hierarchical activity model based on BoW representations, although the approach can be extended to hierarchical models in general. 

\input{hierarchicalModel}

\input{learning}

\input{inference}

% aybe the video representation must be located in experiments
%input{videoRepresentation}