Automatically generated by Mendeley 1.8.4
Any changes to this file will be lost if it is regenerated by Mendeley.

@article{Epstein1998,
abstract = {Medial temporal brain regions such as the hippocampal formation and parahippocampal cortex have been generally implicated in navigation and visual memory. However, the specific function of each of these regions is not yet clear. Here we present evidence that a particular area within human parahippocampal cortex is involved in a critical component of navigation: perceiving the local visual environment. This region, which we name the 'parahippocampal place area' (PPA), responds selectively and automatically in functional magnetic resonance imaging (fMRI) to passively viewed scenes, but only weakly to single objects and not at all to faces. The critical factor for this activation appears to be the presence in the stimulus of information about the layout of local space. The response in the PPA to scenes with spatial layout but no discrete objects (empty rooms) is as strong as the response to complex meaningful scenes containing multiple objects (the same rooms furnished) and over twice as strong as the response to arrays of multiple objects without three-dimensional spatial context (the furniture from these rooms on a blank background). This response is reduced if the surfaces in the scene are rearranged so that they no longer define a coherent space. We propose that the PPA represents places by encoding the geometry of the local environment.},
author = {Epstein, Russell and Kanwisher, Nancy},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Epstein, Kanwisher - 1998 - A cortical representation of the local visual environment.pdf:pdf},
journal = {Nature},
keywords = {Brain Mapping,Face,Female,Hippocampus,Hippocampus: physiology,Humans,Magnetic Resonance Imaging,Male,Photic Stimulation,Space Perception,Space Perception: physiology,Visual Perception,Visual Perception: physiology},
number = {6676},
pages = {598--601},
pmid = {9560155},
publisher = {Nature Publishing Group},
title = {{A cortical representation of the local visual environment}},
volume = {392},
year = {1998}
}
@inproceedings{Yagnik2007,
address = {New York, New York, USA},
author = {Yagnik, Jay and Islam, Atiq},
booktitle = {Proceedings of the international workshop on Workshop on multimedia information retrieval - MIR '07},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yagnik, Islam - 2007 - Learning people annotation from the web via consistency learning.pdf:pdf},
keywords = {consistency learning,correlation sampling,face recognition,graph sampling,learning from noisy,training sets},
pages = {285},
publisher = {ACM Press},
title = {{Learning people annotation from the web via consistency learning}},
year = {2007}
}
@inproceedings{Andriluka2009,
author = {Andriluka, Mykhaylo and Roth, Stefan and Schiele, Bernt},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Andriluka, Roth, Schiele - 2009 - Pictorial structures revisited People detection and articulated pose estimation.pdf:pdf},
pages = {1014--1021},
publisher = {IEEE},
title = {{Pictorial structures revisited: People detection and articulated pose estimation}},
year = {2009}
}
@inproceedings{Filipovych2008,
author = {Filipovych, Roman and Ribeiro, Eraldo},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Filipovych, Ribeiro - 2008 - Learning human motion models from unsegmented videos.pdf:pdf},
month = jun,
number = {June},
pages = {1--7},
publisher = {IEEE},
title = {{Learning human motion models from unsegmented videos}},
year = {2008}
}
@inproceedings{HanICCV2009,
author = {Han, Dong and Bo, Liefeng and Sminchisescu, Cristian},
booktitle = {ICCV},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Han, Bo, Sminchisescu - 2009 - Selection and Context for Action Recognition.pdf:pdf},
title = {{Selection and Context for Action Recognition}},
year = {2009}
}
@inproceedings{Shechtman2005,
abstract = {We introduce a behavior-based similarity measure which tells us whether two different space-time intensity patterns of two different video segments could have resulted from a similar underlying motion field. This is done directly from the intensity information, without explicitly computing the underlying motions. Such a measure allows us to detect similarity between video segments of differently dressed people performing the same type of activity. It requires no foreground/background segmentation, no prior learning of activities, and no motion estimation or tracking. Using this behavior-based similarity measure, we extend the notion of 2-dimensional image correlation into the 3-dimensional space-time volume, thus allowing to correlate dynamic behaviors and actions. Small space-time video segments (small video clips) are "correlated" against entire video sequences in all three dimensions (x,y, and t). Peak correlation values correspond to video locations with similar dynamic behaviors. Our approach can detect very complex behaviors in video sequences (e.g., ballet movements, pool dives, running water), even when multiple complex activities occur simultaneously within the field-of-view of the camera.},
author = {Shechtman, Eli and Irani, Michal},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shechtman, Irani - 2005 - Space-Time Behavior Based Correlation.pdf:pdf},
pages = {405--412},
publisher = {IEEE},
title = {{Space-Time Behavior Based Correlation}},
volume = {1},
year = {2005}
}
@article{Ogale2005,
author = {Ogale, Abhijit S. and Aloimonos, Yiannis},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ogale, Aloimonos - 2005 - Shape and the Stereo Correspondence Problem.pdf:pdf},
journal = {International Journal of Computer Vision},
month = dec,
number = {3},
pages = {147--162},
title = {{Shape and the Stereo Correspondence Problem}},
volume = {65},
year = {2005}
}
@article{Zacks2001b,
abstract = {Events can be understood in terms of their temporal structure. The authors first draw on several bodies of research to construct an analysis of how people use event structure in perception, understanding, planning, and action. Philosophy provides a grounding for the basic units of events and actions. Perceptual psychology provides an analogy to object perception: Like objects, events belong to categories, and, like objects, events have parts. These relationships generate 2 hierarchical organizations for events: taxonomies and partonomies. Event partonomies have been studied by looking at how people segment activity as it happens. Structured representations of events can relate partonomy to goal relationships and causal structure; such representations have been shown to drive narrative comprehension, memory, and planning. Computational models provide insight into how mental representations might be organized and transformed. These different approaches to event structure converge on an explanation of how multiple sources of information interact in event perception and conception.},
author = {Zacks, Jeffrey M. and Tversky, Barbara},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zacks, Tversky - 2001 - Event structure in perception and conception.pdf:pdf},
journal = {Psychological bulletin},
keywords = {Causality,Cognition,Concept Formation,Concept Formation: classification,Humans,Memory,Models,Perception,Psychological,Time Perception},
number = {1},
pages = {3--21},
pmid = {11271755},
title = {{Event structure in perception and conception}},
volume = {127},
year = {2001}
}
@inproceedings{Blank2005,
author = {Blank, Moshe and Gorelick, Lena and Shechtman, Eli and Irani, Michal and Basri, Ronen},
booktitle = {ICCV},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Blank et al. - 2005 - Actions as Space-Time Shapes.pdf:pdf},
pages = {1395--1402},
publisher = {IEEE},
title = {{Actions as Space-Time Shapes}},
volume = {2},
year = {2005}
}
@inproceedings{Babenko2008,
author = {Babenko, Boris and Doll\'{a}r, Piotr and Tu, Zhuowen and Belongie, Serge},
booktitle = {Faces in Real-Life Images},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Babenko et al. - 2008 - Simultaneous Learning and Alignment Multi-Instance and Multi-Pose Learning.pdf:pdf},
pages = {72--83},
title = {{Simultaneous Learning and Alignment: Multi-Instance and Multi-Pose Learning}},
year = {2008}
}
@article{Gaidon2013,
abstract = {We address the problem of localizing actions, such as opening a door, in hours of challenging video data. We propose a model based on a sequence of atomic action units, termed "actoms", that are semantically meaningful and characteristic for the action. Our Actom Sequence Model (ASM) represents an action as a sequence of histograms of actom-anchored visual features, which can be seen as a temporally structured extension of the bag-of-features. Training requires the annotation of actoms for action examples. At test time, actoms are localized automatically based on a non-parametric model of the distribution of actoms, which also acts as a prior on an action's temporal structure. We present experimental results on two recent benchmarks for action localization: "Coffee and Cigarettes" and the "DLSBP" dataset. We also adapt our approach to a classification-by-localization set-up and demonstrate its applicability on the challenging "Hollywood 2" dataset. We show that our ASM method outperforms the current state of the art in temporal action localization, as well as baselines that localize actions with a sliding window method.},
author = {Gaidon, Adrien and Harchaoui, Zaid and Schmid, Cordelia},
journal = {IEEE TPAMI},
month = mar,
pmid = {23546997},
title = {{Temporal Localization of Actions with Actoms}},
year = {2013}
}
@inproceedings{Quattoni2004a,
author = {Quattoni, Ariadna and Collins, Michael and Darrell, Trevor},
booktitle = {NIPS},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Quattoni, Collins, Darrell - 2004 - Conditional random fields for object recognition.pdf:pdf},
title = {{Conditional random fields for object recognition}},
year = {2004}
}
@inproceedings{Yeh,
author = {Yeh, Tom and Lee, John J. and Darrell, Trevor},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yeh, Lee, Darrell - 2009 - Fast concurrent object localization and recognition.pdf:pdf},
month = jun,
pages = {280--287},
publisher = {IEEE},
title = {{Fast concurrent object localization and recognition}},
year = {2009}
}
@inproceedings{Savarese2006,
author = {Savarese, Silvio and Winn, John and Criminisi, Antonio},
booktitle = {CVPR},
title = {Discriminative Object Class Models of Appearance and Shape by Correlatons},
year = {2006}
}
@inproceedings{Packer2012,
author = {Packer, Benjamin and Saenko, Kate and Koller, Daphne},
booktitle = {CVPR},
month = jun,
pages = {1378--1385},
publisher = {IEEE},
title = {{A combined pose, object, and feature model for action understanding}},
year = {2012}
}
@inproceedings{Yuen2009,
author = {Yuen, Jenny and Russell, Bryan C. and Liu, Ce and Torralba, Antonio},
booktitle = {ICCV},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yuen et al. - 2009 - LabelMe video Building a Video Database with Human Annotations(2).pdf:pdf},
pages = {1--8},
title = {{LabelMe video: Building a Video Database with Human Annotations}},
year = {2009}
}
@inproceedings{Brendel2011,
author = {Brendel, William and Todorovic, Sinisa},
booktitle = {ICCV},
title = {Learning spatiotemporal graphs of human activities},
year = {2011}
}
@inproceedings{Ballan2009,
author = {Ballan, Lamberto and Bertini, Marco and {Del Bimbo}, Alberto and Seidenari, Lorenzo and Serra, Giuseppe},
booktitle = {PRAI},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ballan et al. - 2009 - Human Action Recognition and Localization using Spatio-temporal Descriptors and Tracking.pdf:pdf},
keywords = {action classification,bag-of-words,tracking,video annotation},
title = {{Human Action Recognition and Localization using Spatio-temporal Descriptors and Tracking}},
year = {2009}
}
@article{Kanwisher1997,
abstract = {Using functional magnetic resonance imaging (fMRI), we found an area in the fusiform gyrus in 12 of the 15 subjects tested that was significantly more active when the subjects viewed faces than when they viewed assorted common objects. This face activation was used to define a specific region of interest individually for each subject, within which several new tests of face specificity were run. In each of five subjects tested, the predefined candidate "face area" also responded significantly more strongly to passive viewing of (1) intact than scrambled two-tone faces, (2) full front-view face photos than front-view photos of houses, and (in a different set of five subjects) (3) three-quarter-view face photos (with hair concealed) than photos of human hands; it also responded more strongly during (4) a consecutive matching task performed on three-quarter-view faces versus hands. Our technique of running multiple tests applied to the same region defined functionally within individual subjects provides a solution to two common problems in functional imaging: (1) the requirement to correct for multiple statistical comparisons and (2) the inevitable ambiguity in the interpretation of any study in which only two or three conditions are compared. Our data allow us to reject alternative accounts of the function of the fusiform face area (area "FF") that appeal to visual attention, subordinate-level classification, or general processing of any animate or human forms, demonstrating that this region is selectively involved in the perception of faces.},
author = {Kanwisher, Nancy and McDermott, Josh and Chun, Marvin M.},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kanwisher, McDermott, Chun - 1997 - The fusiform face area a module in human extrastriate cortex specialized for face perception.pdf:pdf},
journal = {The Journal of Neuroscience},
keywords = {Adult,Discrimination Learning,Discrimination Learning: physiology,Face,Female,Functional Laterality,Functional Laterality: physiology,Humans,Magnetic Resonance Imaging,Male,Pattern Recognition,Visual,Visual Cortex,Visual Cortex: physiology,Visual Pathways,Visual Pathways: physiology,Visual Perception,Visual Perception: physiology,Visual: physiology},
month = jun,
number = {11},
pages = {4302--11},
pmid = {9151747},
title = {{The fusiform face area: a module in human extrastriate cortex specialized for face perception}},
volume = {17},
year = {1997}
}
@inproceedings{Sung2012,
author = {Sung, Jaeyong and Ponce, Colin and Selman, Bart and Saxena, Ashutosh},
booktitle = {ICRA},
title = {Unstructured Human Activity Detection from {RGBD} Images},
year = {2012}
}
@article{Aggarwal2011,
author = {Aggarwal, J. K. and Ryoo, Michael S.},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Aggarwal, Ryoo - 2011 - Human activity analysis.pdf:pdf},
journal = {ACM Computing Surveys},
month = apr,
number = {3},
pages = {16:1--16:43},
title = {{Human activity analysis}},
volume = {43},
year = {2011}
}
@inproceedings{Filipovych2008a,
author = {Filipovych, Roman and Ribeiro, Eraldo},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Filipovych, Ribeiro - 2008 - Recognizing primitive interactions by exploring actor-object states.pdf:pdf},
pages = {1--7},
publisher = {IEEE},
title = {{Recognizing primitive interactions by exploring actor-object states}},
year = {2008}
}
@article{Quattoni2007,
author = {Quattoni, Ariadna and Wang, Sy Bor and Morency, Louis-Philippe and Collins, Michael and Darrell, Trevor},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Quattoni et al. - 2007 - Hidden conditional random fields..pdf:pdf},
journal = {IEEE TPAMI},
keywords = {Algorithms,Artificial Intelligence,Automated,Automated: methods,Computer Simulation,Computer-Assisted,Computer-Assisted: methods,Data Interpretation,Image Enhancement,Image Enhancement: methods,Image Interpretation,Markov Chains,Models,Pattern Recognition,Reproducibility of Results,Sensitivity and Specificity,Statistical},
month = oct,
number = {10},
pages = {1848--53},
pmid = {17699927},
title = {{Hidden conditional random fields.}},
volume = {29},
year = {2007}
}
@inproceedings{Li2005,
author = {Li, Chunming and Xu, Chenyang and Gui, Changfeng and Fox, Martin D.},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - 2005 - Level Set Evolution without Re-Initialization A New Variational Formulation.pdf:pdf},
pages = {430--436},
publisher = {IEEE},
title = {{Level Set Evolution without Re-Initialization: A New Variational Formulation}},
year = {2005}
}
@inproceedings{Dollar2008,
author = {Doll\'{a}r, Piotr and Babenko, Boris and Belongie, Serge and Perona, Pietro and Tu, Zhuowen},
booktitle = {ECCV},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Doll\'{a}r et al. - 2008 - Multiple component learning for object detection.pdf:pdf},
number = {mil},
pages = {211--224},
publisher = {Springer},
title = {{Multiple component learning for object detection}},
year = {2008}
}
@inproceedings{Ikizler2008,
author = {Ikizler, Nazli and Cinbis, R. Gokberk and Pehlivan, Selen and Duygulu, Pinar},
booktitle = {ICPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ikizler et al. - 2008 - Recognizing actions from still images.pdf:pdf},
month = dec,
pages = {1--4},
publisher = {IEEE},
title = {{Recognizing actions from still images}},
year = {2008}
}
@inproceedings{Wang2008,
author = {Wang, Yang and Mori, Greg},
booktitle = {NIPS},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang, Mori - 2008 - Learning a discriminative hidden part model for human action recognition.pdf:pdf},
title = {{Learning a discriminative hidden part model for human action recognition}},
year = {2008}
}
@inproceedings{Packer2010,
author = {Packer, Benjamin and Gould, Stephen and Koller, Daphne},
booktitle = {ECCV},
title = {{A Unified Contour-Pixel Model for Figure-Ground Segmentation.}},
year = {2010}
}
@phdthesis{Zaimi2005,
author = {Zaimi, Adi},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zaimi - 2005 - The Dynamics of Brain Interactivity Underlying Comprehension of Everyday Visual Action.pdf:pdf},
school = {Rutgers, The State University of New Jersey},
title = {{The Dynamics of Brain Interactivity Underlying Comprehension of Everyday Visual Action}},
year = {2005}
}
@inproceedings{Lafferty2001,
author = {Lafferty, John and McCallum, Andrew and Pereira, Fernando},
booktitle = {ICML},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lafferty, McCallum, Pereira - 2001 - Conditional random fields Probabilistic models for segmenting and labeling sequence data.pdf:pdf},
pages = {282--289},
title = {{Conditional random fields: Probabilistic models for segmenting and labeling sequence data}},
year = {2001}
}
@article{Bobick2001,
author = {Bobick, Aaron F. and Davis, James W.},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bobick, Davis - 2001 - The recognition of human movement using temporal templates.pdf:pdf},
journal = {TPAMI},
number = {3},
pages = {257--267},
title = {{The recognition of human movement using temporal templates}},
volume = {23},
year = {2001}
}
@inproceedings{Ali2007a,
author = {Ali, Saad and Basharat, Arslan and Shah, Mubarak},
booktitle = {ICCV},
pages = {1--8},
publisher = {IEEE},
title = {{Chaotic Invariants for Human Action Recognition}},
year = {2007}
}
@misc{Microsoft2012,
author = {Microsoft},
title = {{Kinect for Windows SDK}},
year = {2012}
}
@inproceedings{Ren2007,
author = {Ren, Xiaofeng and Malik, Jitendra},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ren, Malik - 2007 - Tracking as Repeated FigureGround Segmentation.pdf:pdf},
month = jun,
pages = {1--8},
publisher = {IEEE},
title = {{Tracking as Repeated Figure/Ground Segmentation}},
year = {2007}
}
@article{Gupta2009a,
abstract = {Interpretation of images and videos containing humans interacting with different objects is a daunting task. It involves understanding scene/event, analyzing human movements, recognizing manipulable objects, and observing the effect of the human movement on those objects. While each of these perceptual tasks can be conducted independently, recognition rate improves when interactions between them are considered. Motivated by psychological studies of human perception, we present a Bayesian approach which integrates various perceptual tasks involved in understanding human-object interactions. Previous approaches to object and action recognition rely on static shape/appearance feature matching and motion analysis, respectively. Our approach goes beyond these traditional approaches and applies spatial and functional constraints on each of the perceptual elements for coherent semantic interpretation. Such constraints allow us to recognize objects and actions when the appearances are not discriminative enough. We also demonstrate the use of such constraints in recognition of actions from static images without using any motion information.},
author = {Gupta, Abhinav and Kembhavi, Aniruddha and Davis, Larry S.},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gupta, Kembhavi, Davis - 2009 - Observing human-object interactions using spatial and functional compatibility for recognition..pdf:pdf},
journal = {IEEE TPAMI},
month = oct,
number = {10},
pages = {1775--89},
pmid = {19696449},
title = {{Observing human-object interactions: using spatial and functional compatibility for recognition.}},
volume = {31},
year = {2009}
}
@inproceedings{Russell2009,
author = {Russell, Bryan C. and Efros, Alexei A. and Sivic, Josef and Freeman, William T. and Zisserman, Andrew},
booktitle = {NIPS},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Russell et al. - 2009 - Segmenting Scenes by Matching Image Composites.pdf:pdf},
pages = {1--9},
title = {{Segmenting Scenes by Matching Image Composites}},
year = {2009}
}
@inproceedings{Yang2010,
author = {Yang, Weilong and Wang, Yang and Mori, Greg},
booktitle = {CVPR},
month = jun,
pages = {2030--2037},
publisher = {IEEE},
title = {{Recognizing human actions from still images with latent poses}},
year = {2010}
}
@inproceedings{Sivic2009,
author = {Sivic, Josef and Everingham, Mark and Zisserman, Andrew},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sivic, Everingham, Zisserman - 2009 - “Who are you” – Learning person specific classifiers from video.pdf:pdf},
month = jun,
number = {i},
pages = {1145--1152},
publisher = {IEEE},
title = {{“Who are you?” – Learning person specific classifiers from video}},
year = {2009}
}
@inproceedings{Marszalek2009,
author = {Marszalek, Marcin and Laptev, Ivan and Schmid, Cordelia},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Marszalek, Laptev, Schmid - 2009 - Actions in context.pdf:pdf},
pages = {2929--2936},
publisher = {IEEE},
title = {{Actions in context}},
year = {2009}
}
@article{Tversky2004,
author = {Tversky, Barbara and Zacks, Jeffrey M. and Lee, Paul},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tversky, Zacks, Lee - 2004 - Events by Hands and Feet.pdf:pdf},
journal = {Spatial Cognition \& Computation},
keywords = {and n000140210534 to stanford,bt,correspondence concerning this article,edu,events,grants number,in part by office,maps,n000140110717,nooo14-pp-1-o649,of naval research,partonomy,parts,psych,routes,should be addressed to,stanford,taxonomy,the manuscript was supported,university},
month = mar,
number = {1},
pages = {5--14},
title = {{Events by Hands and Feet}},
volume = {4},
year = {2004}
}
@inproceedings{Ferrari2009,
author = {Ferrari, Vittorio and Marin-Jimenez, Manuel and Zisserman, Andrew},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ferrari, Marin-Jimenez, Zisserman - 2009 - Pose search Retrieving people using their pose.pdf:pdf},
pages = {1--8},
publisher = {IEEE},
title = {{Pose search: Retrieving people using their pose}},
year = {2009}
}
@inproceedings{Pirsiavash2009,
author = {Pirsiavash, Hamed and Ramanan, Deva and Fowlkes, Charless},
booktitle = {NIPS},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pirsiavash, Ramanan, Fowlkes - 2009 - Bilinear classifiers for visual recognition.pdf:pdf},
pages = {1--9},
title = {{Bilinear classifiers for visual recognition}},
year = {2009}
}
@article{Oikonomopoulos2005,
author = {Oikonomopoulos, A. and Patras, I. and Pantic, M.},
journal = {IEEE Transactions on Systems, Man and Cybernetics, Part B (Cybernetics)},
month = jun,
number = {3},
pages = {710--719},
title = {{Spatiotemporal salient points for visual recognition of human actions}},
volume = {36},
year = {2005}
}
@inproceedings{Ikizler2010,
author = {Ikizler-Cinbis, Nazli and Sclaroff, Stan},
booktitle = {ECCV},
title = {{Object, Scene and Actions: Combining Multiple Features for Human Action Recognition}},
year = {2010}
}
@article{Laptev2005,
author = {Laptev, Ivan},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Laptev - 2005 - On Space-Time Interest Points.pdf:pdf},
journal = {IJCV},
keywords = {interest points,matching,scale selection,scale-space,video interpretation},
number = {2-3},
pages = {107--123},
title = {{On Space-Time Interest Points}},
volume = {64},
year = {2005}
}
@inproceedings{Stadler,
author = {Stadler, Severin and Grabner, Helmut and {Van Gool}, Luc},
booktitle = {ECCV},
title = {{Dynamic Objectness for Adaptive Tracking}},
year = {2012}
}
@article{Yilmaz2006,
author = {Yilmaz, Alper and Javed, Omar and Shah, Mubarak},
journal = {ACM Computing Surveys},
month = dec,
number = {4},
title = {{Object tracking}},
volume = {38},
year = {2006}
}
@inproceedings{Nowozin2007,
author = {Nowozin, Sebastian and Bakir, Gokhan and Tsuda, Koji},
booktitle = {ICCV},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nowozin, Bakir, Tsuda - 2007 - Discriminative Subsequence Mining for Action Classification.pdf:pdf},
month = oct,
pages = {1--8},
publisher = {IEEE},
title = {{Discriminative Subsequence Mining for Action Classification}},
year = {2007}
}
@inproceedings{Lan2010,
author = {Lan, Tian and Wang, Yang and Yang, Weilong and Mori, Greg},
booktitle = {NIPS},
title = {{Beyond Actions: Discriminative Models for Contextual Group Activities}},
year = {2010}
}
@inproceedings{Fanti2005,
author = {Fanti, Claudio and Zelnik-Manor, Lihi and Perona, Pietro},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fanti, Zelnik-Manor, Perona - 2005 - Hybrid Models for Human Motion Recognition.pdf:pdf},
pages = {1166--1173},
publisher = {IEEE},
title = {{Hybrid Models for Human Motion Recognition}},
volume = {1},
year = {2005}
}
@inproceedings{Elhamifar2012,
author = {Elhamifar, Ehsan and Sapiro, Guillermo and Vidal, Rene},
booktitle = {CVPR},
month = jun,
pages = {1600--1607},
publisher = {IEEE},
title = {{See all by looking at a few: Sparse modeling for finding representative objects}},
year = {2012}
}
@article{Sminchisescu2006,
author = {Sminchisescu, Cristian and Kanaujia, Atul and Metaxas, Dimitris},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sminchisescu, Kanaujia, Metaxas - 2006 - Conditional models for contextual human motion recognition.pdf:pdf},
journal = {CVIU},
keywords = {conditional models,discriminative models,feature selection,gression,hidden,human motion recognition,markov models,markov random elds,multiclass logistic re-,optimization},
month = nov,
number = {2-3},
pages = {210--220},
title = {{Conditional models for contextual human motion recognition}},
volume = {104},
year = {2006}
}
@article{Popoola2012,
author = {Popoola, Oluwatoyin P. and Wang, Kejun},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Popoola, Wang - 2012 - Video-Based Abnormal Human Behavior Recognition — A Review.pdf:pdf},
journal = {IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
month = nov,
number = {6},
pages = {865--878},
title = {{Video-Based Abnormal Human Behavior Recognition—A Review}},
volume = {42},
year = {2012}
}
@inproceedings{Niebles2007,
author = {Niebles, Juan Carlos and Fei-Fei, Li},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Niebles, Fei-Fei - 2007 - A Hierarchical Model of Shape and Appearance for Human Action Classification.pdf:pdf},
month = jun,
pages = {1--8},
publisher = {IEEE},
title = {{A Hierarchical Model of Shape and Appearance for Human Action Classification}},
year = {2007}
}
@inproceedings{Wu2007,
author = {Wu, Jianxin and Osuntogun, Adebola and Choudhury, Tanzeem and Philipose, Matthai and Rehg, James M.},
booktitle = {ICCV},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wu et al. - 2007 - A Scalable Approach to Activity Recognition based on Object Use.pdf:pdf},
pages = {1--8},
publisher = {IEEE},
title = {{A Scalable Approach to Activity Recognition based on Object Use}},
year = {2007}
}
@article{Turaga2008,
author = {Turaga, Pavan and Chellappa, Rama and Subrahmanian, V. S. and Udrea, Octavian},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Turaga et al. - 2008 - Machine Recognition of Human Activities A Survey.pdf:pdf},
journal = {IEEE Transactions on Circuits and Systems for Video Technology},
month = nov,
number = {11},
pages = {1473--1488},
title = {{Machine Recognition of Human Activities: A Survey}},
volume = {18},
year = {2008}
}
@inproceedings{Wang2007,
author = {Wang, Xiaogang and Ma, Xiaoxu and Grimson, Eric},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang, Ma, Grimson - 2007 - Unsupervised Activity Perception by Hierarchical Bayesian Models.pdf:pdf},
month = jun,
pages = {1--8},
publisher = {IEEE},
title = {{Unsupervised Activity Perception by Hierarchical Bayesian Models}},
year = {2007}
}
@article{VanRooij2008,
author = {van Rooij, Iris and Haselager, Willem and Bekkering, Harold},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/van Rooij, Haselager, Bekkering - 2008 - Goals are not implied by actions, but inferred from actions and contexts.pdf:pdf},
journal = {Behavioral and Brain Sciences},
number = {01},
pages = {38--39},
title = {{Goals are not implied by actions, but inferred from actions and contexts}},
volume = {31},
year = {2008}
}
@inproceedings{Ikizler-Cinbis2009,
author = {Ikizler-Cinbis, Nazli and Cinbis, R. Gokberk and Sclaroff, Stan},
booktitle = {ICCV},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ikizler-Cinbis, Cinbis, Sclaroff - 2009 - Learning Actions From the Web.pdf:pdf},
title = {{Learning Actions From the Web}},
year = {2009}
}
@inproceedings{Wong2007,
author = {Wong, Shu-Fai and Kim, Tae-Kyun and Cipolla, Roberto},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wong, Kim, Cipolla - 2007 - Learning Motion Categories using both Semantic and Structural Information.pdf:pdf},
pages = {1--6},
publisher = {IEEE},
title = {{Learning Motion Categories using both Semantic and Structural Information}},
year = {2007}
}
@article{Burges1998,
author = {Burges, Christopher J. C.},
journal = {Data Min. Knowl. Discov.},
number = {2},
pages = {121----167},
title = {{A Tutorial on Support Vector Machines for Pattern Recognition}},
volume = {2},
year = {1998}
}
@inproceedings{Weber2000,
author = {Weber, Markus and Welling, Max and Perona, Pietro},
booktitle = {ECCV},
pages = {18--32},
title = {{Unsupervised Learning of Models for Recognition}},
year = {2000}
}
@article{Harris1988,
abstract = {Consistency of image edge filtering is of prime importance for 3D interpretation of image sequences using feature tracking algorithms. To cater for image regions containing texture and isolated features, a combined corner and edge detector based on the local auto-correlation function is utilised, and it is shown to perform with good consistency on natural imagery.},
author = {Harris, Chris and Stephens, Mike},
journal = {Proc 4th Alvey Vision Conference},
title = {{A combined edge and corner detector}},
year = {1988}
}
@article{Saxena2009,
abstract = {We consider the problem of estimating detailed 3D structure from a single still image of an unstructured environment. Our goal is to create 3D models that are both quantitatively accurate as well as visually pleasing. For each small homogeneous patch in the image, we use a Markov Random Field (MRF) to infer a set of "plane parameters" that capture both the 3D location and 3D orientation of the patch. The MRF, trained via supervised learning, models both image depth cues as well as the relationships between different parts of the image. Other than assuming that the environment is made up of a number of small planes, our model makes no explicit assumptions about the structure of the scene; this enables the algorithm to capture much more detailed 3D structure than does prior art and also give a much richer experience in the 3D flythroughs created using image-based rendering, even for scenes with significant nonvertical structure. Using this approach, we have created qualitatively correct 3D models for 64.9 percent of 588 images downloaded from the Internet. We have also extended our model to produce large-scale 3D models from a few images.},
author = {Saxena, Ashutosh and Sun, Min and Ng, Andrew Y.},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Saxena, Sun, Ng - 2009 - Make3D learning 3D scene structure from a single still image..pdf:pdf},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Algorithms,Artificial Intelligence,Automated,Automated: methods,Computer-Assisted,Computer-Assisted: methods,Image Enhancement,Image Enhancement: methods,Image Interpretation,Imaging,Information Storage and Retrieval,Information Storage and Retrieval: methods,Pattern Recognition,Photography,Photography: methods,Reproducibility of Results,Sensitivity and Specificity,Three-Dimensional,Three-Dimensional: methods},
month = may,
number = {5},
pages = {824--40},
pmid = {19299858},
title = {{Make3D: learning 3D scene structure from a single still image.}},
volume = {31},
year = {2009}
}
@article{Csibra2007,
abstract = {Humans show a strong and early inclination to interpret observed behaviours of others as goal-directed actions. We identify two main epistemic functions that this 'teleological obsession' serves: on-line prediction and social learning. We show how teleological action interpretations can serve these functions by drawing on two kinds of inference ('action-to-goal' or 'goal-to-action'), and argue that both types of teleological inference constitute inverse problems that can only be solved by further assumptions. We pinpoint the assumptions that the three currently proposed mechanisms of goal attribution (action-effect associations, simulation procedures, and teleological reasoning) imply, and contrast them with the functions they are supposed to fulfil. We argue that while action-effect associations and simulation procedures are generally well suited to serve on-line action monitoring and prediction, social learning of new means actions and artefact functions requires the inferential productivity of teleological reasoning.},
author = {Csibra, Gergely and Gergely, Gy\"{o}rgy},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Csibra, Gergely - 2007 - 'Obsessed with goals' functions and mechanisms of teleological interpretation of actions in humans.pdf:pdf},
journal = {Acta psychologica},
keywords = {Cognition,Cognition: physiology,Goals,Habituation,Humans,Infant,Intention,Learning,Learning: physiology,Motor Activity,Motor Activity: physiology,Obsessive Behavior,Obsessive Behavior: psychology,Psychomotor Performance,Psychomotor Performance: physiology,Psychophysiologic,Psychophysiologic: physiology,Social Perception},
number = {1},
pages = {60--78},
pmid = {17081489},
title = {{'Obsessed with goals': functions and mechanisms of teleological interpretation of actions in humans}},
volume = {124},
year = {2007}
}
@inproceedings{Wang2008a,
author = {Wang, Yang and Mori, Greg},
booktitle = {ECCV},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang, Mori - 2008 - Multiple Tree Models for Occlusion and Spatial Constraints in Human Pose Estimation.pdf:pdf},
title = {{Multiple Tree Models for Occlusion and Spatial Constraints in Human Pose Estimation}},
year = {2008}
}
@inproceedings{Sadanand2012,
author = {Sadanand, Sreemanananth and Corso, Jason J.},
booktitle = {CVPR},
month = jun,
pages = {1234--1241},
publisher = {IEEE},
title = {{Action bank: A high-level representation of activity in video}},
year = {2012}
}
@article{Felzenszwalb2005,
author = {Felzenszwalb, Pedro F. and Huttenlocher, Daniel P.},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Felzenszwalb, Huttenlocher - 2005 - Pictorial Structures for Object Recognition.pdf:pdf},
journal = {IJCV},
keywords = {energy minimization,part-based object recognition,statistical models},
month = jan,
number = {1},
pages = {55--79},
title = {{Pictorial Structures for Object Recognition}},
volume = {61},
year = {2005}
}
@phdthesis{Escorcia2011,
author = {Escorcia, Victor and Davila, Maria A.},
school = {Universidad del Norte},
title = {{Reconocimiento de Acciones Humanas en Imagenes RGBD}},
year = {2011}
}
@article{Buch2011,
author = {Buch, Norbert and Velastin, Sergio A. and Orwell, James},
journal = {IEEE Transactions on Intelligent Transportation Systems},
month = sep,
number = {3},
pages = {920--939},
title = {{A Review of Computer Vision Techniques for the Analysis of Urban Traffic}},
volume = {12},
year = {2011}
}
@inproceedings{Jhuang2007,
author = {Jhuang, Hueihan and Serre, Thomas and Wolf, Lior and Poggio, Tomaso},
booktitle = {ICCV},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jhuang et al. - 2007 - A Biologically Inspired System for Action Recognition.pdf:pdf},
month = oct,
number = {2},
pages = {1--8},
publisher = {IEEE},
title = {{A Biologically Inspired System for Action Recognition}},
volume = {1},
year = {2007}
}
@inproceedings{Dollar2005,
author = {Doll\'{a}r, Piotr and Rabaud, Vincent and Cottrell, Garrison and Belongie, Serge},
booktitle = {VSPETS},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Doll\'{a}r et al. - 2005 - Behavior Recognition via Sparse Spatio-Temporal Features.pdf:pdf},
title = {{Behavior Recognition via Sparse Spatio-Temporal Features}},
year = {2005}
}
@inproceedings{Memarzadeh2012,
author = {Memarzadeh, Milad and Heydarian, Arsalan and Golparvar-Fard, Mani and Niebles, Juan Carlos},
booktitle = {International Conference on Computing in Civil Engineering},
title = {{Real-Time and Automated Recognition and 2D Tracking of Construction Workers and Equipment from Site Video Streams}},
year = {2012}
}
@inproceedings{Chockalingam2009,
author = {Chockalingam, Prakash and Birchfield, Stanley T. and Pradeep, Nalin},
booktitle = {ICCV},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chockalingam, Pradeep, Birchfield - 2009 - Adaptive fragments-based tracking of non-rigid objects using level sets.pdf:pdf},
number = {September},
publisher = {IEEE},
title = {{Adaptive fragments-based tracking of non-rigid objects using level sets}},
year = {2009}
}
@inproceedings{Laxton2007,
author = {Laxton, Benjamin and Lim, Jongwoo and Kriegman, David},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Laxton, Lim, Kriegman - 2007 - Leveraging temporal, contextual and ordering constraints for recognizing complex activities in video.pdf:pdf},
month = jun,
pages = {1--8},
publisher = {IEEE},
title = {{Leveraging temporal, contextual and ordering constraints for recognizing complex activities in video}},
year = {2007}
}
@inproceedings{Sridhar2010,
author = {Sridhar, Muralikrishna and Cohn, Anthony G. and Hogg, David C.},
booktitle = {AAAI},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sridhar, Cohn, Hogg - 2010 - Unsupervised Learning of Event Classes from Video.pdf:pdf},
pages = {1631--1638},
title = {{Unsupervised Learning of Event Classes from Video}},
year = {2010}
}
@inproceedings{Comaniciu2000,
author = {Comaniciu, Dorin and Ramesh, Visvanathan and Meer, Peter},
booktitle = {CVPR},
pages = {142--149},
publisher = {IEEE},
title = {{Real-time tracking of non-rigid objects using mean shift}},
year = {2000}
}
@inproceedings{Yao2007,
abstract = {This paper presents a large scale general purpose image database with human annotated ground truth. Firstly, an all-in-all labeling framework is proposed to group visual knowledge of three levels: scene level (global geometric description), object level (segmentation, sketch representation, hierarchical decomposition), and low-mid level (2.1D layered representation, object boundary attributes, curve completion, etc.). Much of this data has not appeared in previous databases. In addition, And-Or Graph is used to organize visual elements to facilitate top-down labeling. An annotation tool is developed to realize and integrate all tasks. With this tool, we’ve been able to create a database consisting of more than 636,748 annotated images and video frames. Lastly, the data is organized into 13 common subsets to serve as benchmarks for diverse evaluation endeavors.},
address = {Berlin, Heidelberg},
author = {Yao, Benjamin and Yang, Xiong and Zhu, Song-Chun},
booktitle = {EMMCVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yao, Yang, Zhu - 2007 - Introduction to a Large-Scale General Purpose Ground Truth Methodology, Annotation Tool and Benchmarks.pdf:pdf},
pages = {169 -- 183},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Introduction to a Large-Scale General Purpose Ground Truth: Methodology, Annotation Tool and Benchmarks}},
volume = {4679},
year = {2007}
}
@inproceedings{Cao2009,
author = {Cao, Liangliang and Lv, Fengjun and Yan, Shuicheng and Gong, Yihong and Huang, Thomas S.},
booktitle = {ICCV},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cao et al. - 2009 - Action Detection in Complex Scenes with Spatial and Temporal Ambiguities.pdf:pdf},
title = {{Action Detection in Complex Scenes with Spatial and Temporal Ambiguities}},
year = {2009}
}
@inproceedings{Fei-Fei2005,
author = {Fei-Fei, Li and Perona, Pietro},
booktitle = {CVPR},
pages = {524--531},
publisher = {IEEE},
title = {{A Bayesian Hierarchical Model for Learning Natural Scene Categories}},
volume = {2},
year = {2005}
}
@inproceedings{Desai2009,
author = {Desai, Chaitanya and Ramanan, Deva and Fowlkes, Charless},
booktitle = {ICCV},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Desai, Ramanan, Fowlkes - 2009 - Discriminative models for multi-class object layout.pdf:pdf},
month = sep,
publisher = {IEEE},
title = {{Discriminative models for multi-class object layout}},
year = {2009}
}
@article{Wolfe1998,
abstract = {Recent studies of visual perception are bringing us closer to an understanding of what we remember - and what we forget - when we recall a scene.},
author = {Wolfe, Jeremy M.},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wolfe - 1998 - Visual memory what do you know about what you saw.pdf:pdf},
journal = {Current Biology},
keywords = {Humans,Memory,Memory: physiology,Visual Perception,Visual Perception: physiology},
number = {9},
pages = {R303--4},
pmid = {9560330},
title = {{Visual memory: what do you know about what you saw?}},
volume = {8},
year = {1998}
}
@article{Wang2009b,
abstract = {We propose two new models for human action recognition from video sequences using topic models. Video sequences are represented by a novel "bag-of-words" representation, where each frame corresponds to a "word." Our models differ from previous latent topic models for visual recognition in two major aspects: first of all, the latent topics in our models directly correspond to class labels; second, some of the latent variables in previous topic models become observed in our case. Our models have several advantages over other latent topic models used in visual recognition. First of all, the training is much easier due to the decoupling of the model parameters. Second, it alleviates the issue of how to choose the appropriate number of latent topics. Third, it achieves much better performance by utilizing the information provided by the class labels in the training set. We present action classification results on five different data sets. Our results are either comparable to, or significantly better than previously published results on these data sets.},
author = {Wang, Yang and Mori, Greg},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang, Mori - 2009 - Human action recognition by semilatent topic models.pdf:pdf},
journal = {IEEE TPAMI},
keywords = {Algorithms,Automated,Automated: methods,Biological,Cluster Analysis,Human Activities,Human Activities: classification,Humans,Locomotion,Locomotion: physiology,Models,Motion,Movement,Movement: physiology,Pattern Recognition},
month = oct,
number = {10},
pages = {1762--74},
pmid = {19696448},
title = {{Human action recognition by semilatent topic models}},
volume = {31},
year = {2009}
}
@inproceedings{Morency2007,
author = {Morency, Louis-Philippe and Quattoni, Ariadna and Darrell, Trevor},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Morency, Quattoni, Darrell - 2007 - Latent-Dynamic Discriminative Models for Continuous Gesture Recognition.pdf:pdf},
month = jun,
pages = {1--8},
publisher = {IEEE},
title = {{Latent-Dynamic Discriminative Models for Continuous Gesture Recognition}},
year = {2007}
}
@inproceedings{Lee2011,
author = {Lee, Yong Jae and Kim, Jaechul and Grauman, Kristen},
booktitle = {ICCV},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lee, Kim, Grauman - 2011 - Key-segments for video object segmentation.pdf:pdf},
month = nov,
pages = {1995--2002},
publisher = {IEEE},
title = {{Key-segments for video object segmentation}},
year = {2011}
}
@inproceedings{Ramanan2007b,
author = {Ramanan, Deva},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ramanan - 2007 - Using Segmentation to Verify Object Hypotheses.pdf:pdf},
month = jun,
pages = {1--8},
publisher = {IEEE},
title = {{Using Segmentation to Verify Object Hypotheses}},
year = {2007}
}
@inproceedings{Huang2011,
author = {Huang, Zhi Feng and Yang, Weilong and Wang, Yang and Mori, Greg},
booktitle = {BMVC},
pages = {132.1--132.11},
publisher = {British Machine Vision Association},
title = {{Latent Boosting for Action Recognition}},
year = {2011}
}
@inproceedings{Zhao2008,
author = {Zhao, Zhipeng and Elgammal, Ahmed},
booktitle = {FG},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhao, Elgammal - 2008 - Spatiotemporal pyramid representation for recognition of facial expressions and hand gestures.pdf:pdf},
month = sep,
pages = {1--6},
publisher = {IEEE},
title = {{Spatiotemporal pyramid representation for recognition of facial expressions and hand gestures}},
year = {2008}
}
@article{Bennett2008,
author = {Bennett, Brandon and Magee, Derek R. and Cohn, Anthony G. and Hogg, David C.},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bennett et al. - 2008 - Enhanced tracking and recognition of moving objects by reasoning about spatio-temporal continuity.pdf:pdf},
journal = {Image and Vision Computing},
keywords = {continuity,resolving ambiguity,spatial reasoning,temporal reasoning,visual surveillance},
month = jan,
number = {1},
pages = {67--81},
title = {{Enhanced tracking and recognition of moving objects by reasoning about spatio-temporal continuity}},
volume = {26},
year = {2008}
}
@article{Haritaoglu2000,
author = {Haritaoglu, Ismail and Harwood, David and Davis, Larry S.},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Haritaoglu, Harwood, Davis - 2000 - W4 real-time surveillance of people and their activities.pdf:pdf},
journal = {IEEE TPAMI},
number = {8},
pages = {809--830},
title = {{W4: real-time surveillance of people and their activities}},
volume = {22},
year = {2000}
}
@article{Kliper-Gross2012,
abstract = {Recognizing actions in videos is rapidly becoming a topic of much research. To facilitate the development of methods for action recognition, several video collections, along with benchmark protocols, have previously been proposed. In this paper, we present a novel video database, the "Action Similarity LAbeliNg" (ASLAN) database, along with benchmark protocols. The ASLAN set includes thousands of videos collected from the web, in over 400 complex action classes. Our benchmark protocols focus on action similarity (same/not-same), rather than action classification, and testing is performed on never-before-seen actions. We propose this data set and benchmark as a means for gaining a more principled understanding of what makes actions different or similar, rather than learning the properties of particular action classes. We present baseline results on our benchmark, and compare them to human performance. To promote further study of action similarity techniques, we make the ASLAN database, benchmarks, and descriptor encodings publicly available to the research community.},
author = {Kliper-Gross, Orit and Hassner, Tal and Wolf, Lior},
file = {:home/jniebles/Documents/research/papers/Kliper-Gross, Hassner, Wolf - 2012 - The action similarity labeling challenge(2).pdf:pdf},
journal = {IEEE TPAMI},
month = mar,
number = {3},
pages = {615--21},
pmid = {22262724},
title = {{The action similarity labeling challenge.}},
volume = {34},
year = {2012}
}
@inproceedings{Endres2010,
author = {Endres, Ian and Hoiem, Derek},
booktitle = {ECCV},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Endres, Hoiem - 2010 - Category independent object proposals.pdf:pdf},
title = {{Category independent object proposals}},
year = {2010}
}
@article{Viola2004,
author = {Viola, Paul and Jones, Michael J.},
journal = {International Journal of Computer Vision},
month = may,
number = {2},
pages = {137--154},
title = {{Robust Real-Time Face Detection}},
volume = {57},
year = {2004}
}
@inproceedings{Todorovic2012,
author = {Todorovic, Sinisa},
booktitle = {ECCV},
title = {Human Activities as Stochastic {K}ronecker Graphs},
year = {2012}
}
@article{Poppe2010,
author = {Poppe, Ronald},
journal = {Image and Vision Computing},
number = {6},
pages = {976--990},
title = {{A survey on vision-based human action recognition}},
volume = {28},
year = {2010}
}
@inproceedings{Amer2012,
author = {Amer, Mohamed R. and Todorovic, Sinisa},
booktitle = {CVPR},
title = {Sum-product networks for modeling activities with stochastic structure},
year = {2012}
}
@article{Niebles2008a,
author = {Niebles, Juan Carlos and Wang, Hongcheng and Fei-Fei, Li},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Niebles, Wang, Fei-Fei - 2008 - Unsupervised Learning of Human Action Categories Using Spatial-Temporal Words.pdf:pdf},
journal = {IJCV},
keywords = {action categorization,bag of words,spatio-temporal interest points,topic models,unsupervised learning},
number = {3},
pages = {299--318},
title = {{Unsupervised Learning of Human Action Categories Using Spatial-Temporal Words}},
volume = {79},
year = {2008}
}
@inproceedings{Maji2008,
author = {Maji, Subhransu and Berg, Alexander C. and Malik, Jitendra},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Maji, Berg, Malik - 2008 - Classification using intersection kernel support vector machines is efficient.pdf:pdf},
month = jun,
pages = {1--8},
publisher = {IEEE},
title = {{Classification using intersection kernel support vector machines is efficient}},
year = {2008}
}
@inproceedings{Wang2009a,
author = {Wang, Heng and Ullah, Muhammad Muneeb and Klaser, Alexander and Laptev, Ivan and Schmid, Cordelia},
booktitle = {BMVC},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2009 - Evaluation of local spatio-temporal features for action recognition.pdf:pdf},
title = {{Evaluation of local spatio-temporal features for action recognition}},
year = {2009}
}
@inproceedings{Yao2011,
author = {Yao, Bangpeng and Khosla, Aditya and Fei-Fei, Li},
booktitle = {CVPR},
month = jun,
pages = {1577--1584},
publisher = {IEEE},
title = {{Combining randomization and discrimination for fine-grained image categorization}},
year = {2011}
}
@article{Kadir2001,
author = {Kadir, Timor and Brady, Michael},
journal = {IJCV},
number = {2},
pages = {83--105},
title = {{Saliency, Scale and Image Description}},
volume = {45},
year = {2001}
}
@article{Rabiner1989,
author = {Rabiner, Lawrence R.},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rabiner - 1989 - A tutorial on hidden Markov models and selected applications in speech recognition.pdf:pdf},
journal = {Proceedings of the IEEE},
number = {2},
pages = {257--286},
publisher = {Morgan Kaufmann},
title = {{A tutorial on hidden Markov models and selected applications in speech recognition}},
volume = {77},
year = {1989}
}
@inproceedings{Gall2009,
author = {Gall, Juergen and Lempitsky, Victor},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gall, Lempitsky - 2009 - Class-Specific Hough Forests for Object Detection.pdf:pdf},
month = jun,
pages = {1022--1029},
publisher = {IEEE},
title = {{Class-Specific Hough Forests for Object Detection}},
year = {2009}
}
@article{Hard2006,
abstract = {People encode goal-directed behaviors, such as assembling an object, by segmenting them into discrete actions, organized as goal-subgoal hierarchies. Does hierarchical encoding contribute to observational learning? Participants in 3 experiments segmented an object assembly task into coarse and fine units of action and later performed it themselves. Hierarchical encoding, measured by segmentation patterns, correlated with more accurate and more hierarchically structured performance of the later assembly task. Furthermore, hierarchical encoding increased when participants (a) segmented coarse units first, (b) explicitly looked for hierarchical structure, and (c) described actions while segmenting them. Improving hierarchical encoding always led to improvements in learning, as well as a surprising shift toward encoding and executing actions from the actor's spatial perspective instead of the participants' own. Hierarchical encoding facilitates observational learning by organizing perceived actions into a representation that can serve as an action plan.},
author = {Hard, Bridgette Martin and Lozano, Sandra C. and Tversky, Barbara},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hard, Lozano, Tversky - 2006 - Hierarchical encoding of behavior translating perception into action.pdf:pdf},
journal = {Journal of experimental psychology. General},
keywords = {Awareness,Goals,Humans,Imitative Behavior,Intention,Mental Recall,Motivation,Orientation,Pattern Recognition,Problem Solving,Psychomotor Performance,Statistics as Topic,Verbal Behavior,Visual},
number = {4},
pages = {588--608},
pmid = {17087575},
title = {{Hierarchical encoding of behavior: translating perception into action}},
volume = {135},
year = {2006}
}
@inproceedings{Choi2009,
author = {Choi, Wongun and Shahid, Khuram and Savarese, Silvio},
booktitle = {VSWS},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Choi, Shahid, Savarese - 2009 - What are they doing Collective Activity Classification Using Spatio-Temporal Relationship Among People..pdf:pdf},
title = {{What are they doing?: Collective Activity Classification Using Spatio-Temporal Relationship Among People.}},
year = {2009}
}
@inproceedings{Yuan2009,
author = {Yuan, Junsong and Liu, Zicheng and Wu, Ying},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yuan, Liu, Wu - 2009 - Discriminative Subvolume Search for Efficient Action Detection.pdf:pdf},
month = jun,
pages = {2442--2449},
publisher = {IEEE},
title = {{Discriminative Subvolume Search for Efficient Action Detection}},
year = {2009}
}
@inproceedings{Ramanan2006a,
author = {Ramanan, Deva},
booktitle = {NIPS},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ramanan - 2006 - Learning to Parse Images of Articulated Objects.pdf:pdf},
title = {{Learning to Parse Images of Articulated Objects}},
year = {2006}
}
@inproceedings{Damen2009,
author = {Damen, Dima and Hogg, David C.},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Damen, Hogg - 2009 - Recognizing linked events Searching the space of feasible explanations.pdf:pdf},
month = jun,
pages = {927--934},
publisher = {IEEE},
title = {{Recognizing linked events: Searching the space of feasible explanations}},
year = {2009}
}
@inproceedings{Everingham2006,
author = {Everingham, Mark and Sivic, Josef and Zisserman, Andrew},
booktitle = {BMVC},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Everingham, Sivic, Zisserman - 2006 - Hello! my name is... Buffy - automatic naming of characters in TV video.pdf:pdf},
title = {{Hello! my name is... Buffy - automatic naming of characters in TV video}},
year = {2006}
}
@inproceedings{Szatmari2005,
author = {Szatm\'{a}ri, I. and Zarandy, A.},
booktitle = {IMEKO TC10 Technical Diagnostics. 10th International Conference on},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Szatm\'{a}ri, Zarandy - 2005 - High-speed label inspection system for textile industry.pdf:pdf},
keywords = {high speed textile inspection},
pages = {99--106},
title = {{High-speed label inspection system for textile industry}},
volume = {1},
year = {2005}
}
@article{Reynolds2007,
author = {Reynolds, Jeremy R. and Zacks, Jeffrey M. and Braver, Todd S.},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Reynolds, Zacks, Braver - 2007 - A Computational Model of Event Segmentation From Perceptual Prediction.pdf:pdf},
journal = {Computational Studies},
keywords = {and we interact with,as,complex world that is,connectionist model,de ned by change,event perception,how do human perceptual,knowledge structures,objects and,of everyday activities such,people that follow intricate,prediction,systems make sense of,the dynamic complexity characteristic,time,trajectories through space and,we live in a},
pages = {613--643},
title = {{A Computational Model of Event Segmentation From Perceptual Prediction}},
volume = {31},
year = {2007}
}
@article{Forsyth2005,
author = {Forsyth, David A. and Arikan, Okan and Ikemoto, Leslie and O'Brien, James and Ramanan, Deva},
journal = {Foundations and Trends® in Computer Graphics and Vision},
number = {2/3},
pages = {77--254},
title = {{Computational Studies of Human Motion: Part 1, Tracking and Motion Synthesis}},
volume = {1},
year = {2005}
}
@inproceedings{Niebles2008,
author = {Niebles, Juan Carlos and Han, Bohyung and Ferencz, Andras and Fei-Fei, Li},
booktitle = {ECCV},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Niebles et al. - 2008 - Extracting Moving People from Internet Videos(2).pdf:pdf},
pages = {1--14},
title = {{Extracting Moving People from Internet Videos}},
year = {2008}
}
@inproceedings{Deutscher2000,
abstract = {The main challenge in articulated body motion tracking is the
large number of degrees of freedom (around 30) to be recovered. Search
algorithms, either deterministic or stochastic, that search such a space
without constraint, fall foul of exponential computational complexity.
One approach is to introduce constraints: either labelling using markers
or colour coding, prior assumptions about motion trajectories or view
restrictions. Another is to relax constraints arising from articulation,
and track limbs as if their motions were independent. In contrast, we
aim for general tracking without special preparation of objects or
restrictive assumptions. The principal contribution of the paper is the
development of a modified particle filter for search in high dimensional
configuration spaces. It uses a continuation principle based on
annealing to introduce the influence of narrow peaks in the fitness
function, gradually. The new algorithm, termed annealed particle
filtering, is shown to be capable of recovering full articulated body
motion efficiently},
author = {Deutscher, Jonathan and Blake, Andrew and Reid, Ian},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Deutscher, Blake, Reid - 2000 - Articulated body motion capture by annealed particle filtering.pdf:pdf},
pages = {126--133},
publisher = {IEEE},
title = {{Articulated body motion capture by annealed particle filtering}},
volume = {2},
year = {2000}
}
@inproceedings{Sivic2005,
author = {Sivic, Josef and Russell, Bryan C. and Efros, Alexei A. and Zisserman, Andrew and Freeman, William T.},
booktitle = {ICCV},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sivic et al. - 2005 - Discovering objects and their location in images.pdf:pdf},
number = {4},
pages = {370--377},
publisher = {IEEE},
title = {{Discovering objects and their location in images}},
volume = {1},
year = {2005}
}
@inproceedings{LiuCVPR2008,
abstract = {In this paper, we present a novel approach for automatically learning a compact and yet discriminative appearance-based human action model. A video sequence is represented by a bag of spatiotemporal features called video-words by quantizing the extracted 3D interest points (cuboids) from the videos. Our proposed approach is able to automatically discover the optimal number of video-word clusters by utilizing maximization of mutual information(MMI). Unlike the k-means algorithm, which is typically used to cluster spatiotemporal cuboids into video words based on their appearance similarity, MMI clustering further groups the video-words, which are highly correlated to some group of actions. To capture the structural information of the learnt optimal video-word clusters, we explore the correlation of the compact video-word clusters. We use the modified correlogram, which is not only translation and rotation invariant, but also somewhat scale invariant. We extensively test our proposed approach on two publicly available challenging datasets: the KTH dataset and IXMAS multiview dataset. To the best of our knowledge, we are the first to try the bag of video-words related approach on the multiview dataset. We have obtained very impressive results on both datasets.},
author = {Liu, Jingen and Shah, Mubarak},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu, Shah - 2008 - Learning human actions via information maximization.pdf:pdf},
pages = {1--8},
publisher = {IEEE},
title = {{Learning human actions via information maximization}},
year = {2008}
}
@article{Decety1999,
abstract = {Our ability to generate actions and to recognize actions performed by others is the bedrock of our social life. Behavioral evidence suggests that the processes underlying perception and action might share a common representational framework. That is, observers might understand the actions of another individual in terms of the same neural code that they use to produce the same actions themselves. What neurophysiological evidence, if any, supports such a hypothesis? In this article, brain imaging studies addressing this question are reviewed and examined in the light of the functional segregation of the perceptual mechanisms subtending visual recognition and those used for action. We suggest that there are not yet conclusive arguments for a clear neurophysiological substrate supporting a common coding between perception and action.},
author = {Decety, Jean and Gr\`{e}zes, Julie},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Decety, Gr\`{e}zes - 1999 - Neural mechanisms subserving the perception of human actions.pdf:pdf},
journal = {Trends in cognitive sciences},
month = may,
number = {5},
pages = {172--178},
pmid = {10322473},
title = {{Neural mechanisms subserving the perception of human actions}},
volume = {3},
year = {1999}
}
@article{Shah2007,
author = {Shah, Mubarak and Javed, Omar and Shafique, Khurram},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shah, Javed, Shafique - 2007 - Automated Visual Surveillance in Realistic Scenarios.pdf:pdf},
journal = {IEEE Multimedia},
number = {1},
pages = {30--39},
title = {{Automated Visual Surveillance in Realistic Scenarios}},
volume = {14},
year = {2007}
}
@inproceedings{Bibby2008,
author = {Bibby, Charles and Reid, Ian},
booktitle = {ECCV},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bibby, Reid - 2008 - Robust real-time visual tracking using pixel-wise posteriors.pdf:pdf},
pages = {831--844},
publisher = {Springer},
title = {{Robust real-time visual tracking using pixel-wise posteriors}},
year = {2008}
}
@inproceedings{WangQuattoni2006,
author = {Wang, Sy Bor and Quattoni, Ariadna and Morency, Louis-Philippe and Demirdjian, David and Darrell, Trevor},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2006 - Hidden Conditional Random Fields for Gesture Recognition.pdf:pdf},
pages = {1521--1527},
publisher = {IEEE},
title = {{Hidden Conditional Random Fields for Gesture Recognition}},
volume = {2},
year = {2006}
}
@inproceedings{Kuettel2010,
author = {Kuettel, Daniel and Breitenstein, Michael D. and {Van Gool}, Luc and Ferrari, Vittorio},
booktitle = {ECCV},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kuettel et al. - 2010 - What’s going on Discovering Spatio-Temporal Dependencies in Dynamic Scenes.pdf:pdf},
title = {{What’s going on? Discovering Spatio-Temporal Dependencies in Dynamic Scenes}},
year = {2010}
}
@inproceedings{Schuldt2004,
abstract = {Local space-time features capture local events in video and can be adapted to the size, the frequency and the velocity of moving patterns. In this paper we demonstrate how such features can be used for recognizing complex motion patterns. We construct video representations in terms of local space-time features and integrate such representations with SVM classification schemes for recognition. For the purpose of evaluation we introduce a new video database containing 2391 sequences of six human actions performed by 25 people in four different scenarios. The presented results of action recognition justify the proposed method and demonstrate its advantage compared to other relative approaches for action recognition.},
author = {Schuldt, Christian and Laptev, Ivan and Caputo, Barbara},
booktitle = {ICPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schuldt, Laptev, Caputo - 2004 - Recognizing human actions a local SVM approach.pdf:pdf},
pages = {32--36},
publisher = {IEEE},
title = {{Recognizing human actions: a local SVM approach}},
year = {2004}
}
@article{Darrell2010,
author = {Stone, Zak and Zickler, Todd and Darrell, Trevor},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Darrell, Ieee - 2010 - Toward Large-Scale Face Recognition Using Social Network Context.pdf:pdf},
journal = {Proceedings of the IEEE},
keywords = {1,about the,by leveraging contextual information,face,fig,networks present a new,opportunity to develop,photographs shared in online,recognition systems,social,socially aware,the billions of personal},
month = aug,
number = {8},
pages = {1408--1415},
title = {{Toward Large-Scale Face Recognition Using Social Network Context}},
volume = {98},
year = {2010}
}
@article{Ikizler2008a,
author = {Ikizler, Nazli and Forsyth, David A.},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ikizler, Forsyth - 2008 - Searching for Complex Human Activities with No Visual Examples.pdf:pdf},
journal = {IJCV},
keywords = {activity,and,b,c,for,hmm,human action recognition,kinematic tracking is hard,learned directly from data,many parameters to be,models typically have too,motion capture,video retrieval},
number = {3},
pages = {337--357},
title = {{Searching for Complex Human Activities with No Visual Examples}},
volume = {80},
year = {2008}
}
@article{Gruber2007,
author = {Gruber, Amit and Rosen-Zvi, Michal and Weiss, Yair},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gruber, Rosen-Zvi, Weiss - 2007 - Hidden topic markov models.pdf:pdf},
journal = {AISTATS},
publisher = {Citeseer},
title = {{Hidden topic markov models}},
year = {2007}
}
@article{Information1962,
author = {Hu, Ming-Kuei},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Information - 1962 - by Moment.pdf:pdf},
journal = {Information Theory, IRE Transactions on},
pages = {179--187},
title = {{Visual Pattern Recognition by Moment Invariants}},
year = {1962}
}
@article{Kumar2006,
author = {Kumar, Sanjiv},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kumar - 2006 - Discriminative Random Fields.pdf:pdf},
journal = {IJCV},
keywords = {discriminative,discriminative classi ers,graphical models,image classi cation,markov random field,random field,spatial interactions},
month = jun,
number = {2},
pages = {179--201},
title = {{Discriminative Random Fields}},
volume = {68},
year = {2006}
}
@incollection{Joachims1999,
author = {Joachims, Thorsten},
booktitle = {Advances in Kernel Methods: Support Vector Learning},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Joachims - 1999 - Making large scale SVM learning practical.pdf:pdf},
publisher = {MIT Press},
title = {{Making large scale SVM learning practical}},
year = {1999}
}
@article{Henderson2007,
author = {Henderson, John M.},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Henderson - 2007 - Regarding Scenes.pdf:pdf},
journal = {Current Directions in Psychological Science},
keywords = {be apprehended very rapidly,eye movements,for at least 30,gaze control,it has been known,of a scene can,of a single,real-world scene,saliency,scene perception,visual,visual context,well within the duration,years that the gist},
month = aug,
number = {4},
pages = {219--222},
title = {{Regarding Scenes}},
volume = {16},
year = {2007}
}
@inproceedings{YilmazCVPR2005,
abstract = {In this paper, we propose to model an action based on both the shape and the motion of the performing object. When the object performs an action in 3D, the points on the outer boundary of the object are projected as 2D (x, y) contour in the image plane. A sequence of such 2D contours with respect to time generates a spatiotemporal volume (STV) in (x, y, t), which can be treated as 3D object in the (x, y, t) space. We analyze STV by using the differential geometric surface properties to identify action descriptors capturing both spatial and temporal properties. A set of action descriptors is called an action sketch. The first step in our approach is to generate STV by solving the point correspondence problem between consecutive frames. The correspondences are determined using a two-step graph theoretical approach. After the STV is generated, actions descriptors are computed by analyzing the differential geometric properties of STV. Finally, using these descriptors, we perform action recognition, which is also formulated as graph theoretical problem. Several experimental results are presented to demonstrate our approach.},
author = {Yilmaz, Alper and Shah, Mubarak},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yilmaz, Shah - 2005 - Actions Sketch A Novel Action Representation.pdf:pdf},
pages = {984--989},
publisher = {IEEE},
title = {{Actions Sketch: A Novel Action Representation}},
volume = {1},
year = {2005}
}
@inproceedings{Thurau2008,
author = {Thurau, Christian and Hlavac, Vaclav},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Thurau, Hlavac - 2008 - Pose primitive based human action recognition in videos or still images.pdf:pdf},
title = {{Pose primitive based human action recognition in videos or still images}},
year = {2008}
}
@article{Fergus2007,
author = {Fergus, Rob and Perona, Pietro and Zisserman, Andrew},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fergus, Perona, Zisserman - 2007 - Weakly Supervised Scale-Invariant Learning of Models for Visual Recognition.pdf:pdf},
journal = {IJCV},
keywords = {constellation model,object recognition,parts and structure model,semi-supervised learning},
number = {3},
pages = {273--303},
title = {{Weakly Supervised Scale-Invariant Learning of Models for Visual Recognition}},
volume = {71},
year = {2007}
}
@inproceedings{Yao2011,
author = {Yao, Bangpeng and Jiang, Xiaoye and Khosla, Aditya and Lin, Andy Lai and Guibas, Leonidas and Fei-Fei, Li},
booktitle = {ICCV},
month = nov,
pages = {1331--1338},
publisher = {IEEE},
title = {{Human action recognition by learning bases of action attributes and parts}},
year = {2011}
}
@article{Bar2004,
author = {Bar, Moshe},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bar - 2004 - Visual objects in context.pdf:pdf},
journal = {Nature reviews in Neuroscience},
keywords = {Animals,Brain,Brain: physiology,Humans,Nerve Net,Nerve Net: physiology,Pattern Recognition,Photic Stimulation,Photic Stimulation: methods,Visual,Visual Perception,Visual Perception: physiology,Visual: physiology},
number = {8},
pages = {617--29},
pmid = {15263892},
title = {{Visual objects in context}},
volume = {5},
year = {2004}
}
@inproceedings{Heydarian2012,
author = {Heydarian, Arsalan and Golparvar-Fard, Mani and Niebles, Juan Carlos},
booktitle = {Construction Research Congress},
title = {{Automated Visual Recognition of Construction Equipment Actions Using Spatio-Temporal Features and Multiple Binary Support Vector Machines}},
year = {2012}
}
@inproceedings{Liu2011,
author = {Liu, Jingen and Kuipers, Benjamin and Savarese, Silvio},
booktitle = {CVPR},
month = jun,
pages = {3337--3344},
publisher = {IEEE},
title = {{Recognizing human actions by attributes}},
year = {2011}
}
@inproceedings{Gu2009,
author = {Gu, Chunhui and Lim, Joseph J. and Arbelaez, Pablo and Malik, Jitendra},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gu et al. - 2009 - Recognition using regions.pdf:pdf},
month = jun,
number = {2},
pages = {1030--1037},
publisher = {IEEE},
title = {{Recognition using regions}},
year = {2009}
}
@inproceedings{Cour2009,
author = {Cour, Timothee and Sapp, Benjamin and Jordan, Chris and Taskar, Ben},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cour et al. - 2009 - Learning from ambiguously labeled images.pdf:pdf},
pages = {919--926},
publisher = {IEEE},
title = {{Learning from ambiguously labeled images}},
year = {2009}
}
@article{Ramanan2007a,
abstract = {An open vision problem is to automatically track the articulations of people from a video sequence. This problem is difficult because one needs to determine both the number of people in each frame and estimate their configurations. But, finding people and localizing their limbs is hard because people can move fast and unpredictably, can appear in a variety of poses and clothes, and are often surrounded by limb-like clutter. We develop a completely automatic system that works in two stages; it first builds a model of appearance of each person in a video and then it tracks by detecting those models in each frame ("tracking by model-building and detection"). We develop two algorithms that build models; one bottom-up approach groups together candidate body parts found throughout a sequence. We also describe a top-down approach that automatically builds people-models by detecting convenient key poses within a sequence. We finally show that building a discriminative model of appearance is quite helpful since it exploits structure in a background (without background-subtraction). We demonstrate the resulting tracker on hundreds of thousands of frames of unscripted indoor and outdoor activity, a feature-length film ("Run Lola Run"), and legacy sports footage (from the 2002 World Series and 1998 Winter Olympics). Experiments suggest that our system 1) can count distinct individuals, 2) can identify and track them, 3) can recover when it loses track, for example, if individuals are occluded or briefly leave the view, 4) can identify body configuration accurately, and 5) is not dependent on particular models of human motion.},
author = {Ramanan, Deva and Forsyth, David A. and Zisserman, Andrew},
journal = {IEEE TPAMI},
keywords = {Algorithms,Artificial Intelligence,Automated,Automated: methods,Computer-Assisted,Computer-Assisted: methods,Humans,Image Enhancement,Image Enhancement: methods,Image Interpretation,Imaging,Information Storage and Retrieval,Information Storage and Retrieval: methods,Movement,Pattern Recognition,Reproducibility of Results,Sensitivity and Specificity,Three-Dimensional,Three-Dimensional: methods,Video Recording,Video Recording: methods,Whole Body Imaging,Whole Body Imaging: methods},
month = jan,
number = {1},
pages = {65--81},
pmid = {17108384},
title = {{Tracking people by learning their appearance}},
volume = {29},
year = {2007}
}
@inproceedings{Xiang2005,
abstract = {A novel framework is developed for automatic behaviour profiling and abnormality sampling/detection without any manual labelling of the training dataset. Natural grouping of behaviour patterns is discovered through unsupervised model selection and feature selection on the eigenvectors of a normalised affinity matrix. Our experiments demonstrate that a behaviour model trained using an unlabelled dataset is superior to those trained using the same but labelled dataset in detecting abnormality from an unseen video},
author = {Xiang, Tao and Gong, Shaogang},
booktitle = {ICCV},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xiang, Gong - 2005 - Video Behaviour Profiling and Abnormality Detection without Manual Labelling.pdf:pdf},
pages = {1238--1245},
publisher = {IEEE},
title = {{Video Behaviour Profiling and Abnormality Detection without Manual Labelling}},
volume = {2},
year = {2005}
}
@inproceedings{Hofmann1999,
address = {New York, New York, USA},
author = {Hofmann, Thomas},
booktitle = {ACM SIGIR},
pages = {50--57},
publisher = {ACM Press},
title = {{Probabilistic latent semantic indexing}},
year = {1999}
}
@inproceedings{Yu2009a,
address = {New York, New York, USA},
author = {Yu, Chun-Nam John and Joachims, Thorsten},
booktitle = {ICML},
pages = {1--8},
publisher = {ACM Press},
title = {{Learning structural SVMs with latent variables}},
year = {2009}
}
@inproceedings{Lan2004,
author = {Lan, Xiangyang and Huttenlocher, Daniel P.},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lan, Huttenlocher - 2004 - A unified spatio-temporal articulated model for tracking.pdf:pdf},
pages = {722--729},
publisher = {IEEE},
title = {{A unified spatio-temporal articulated model for tracking}},
year = {2004}
}
@inproceedings{Rzeszotarski2008,
author = {Rzeszotarski, Dariusz and Wi?cek, Bogus?aw},
booktitle = {Components},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rzeszotarski, Wi?cek - 2008 - Calibration for 3D Reconstruction of Thermal Images.pdf:pdf},
pages = {0--3},
title = {{Calibration for 3D Reconstruction of Thermal Images}},
year = {2008}
}
@article{Everingham2009,
author = {Everingham, Mark and Sivic, Josef and Zisserman, Andrew},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Everingham, Sivic, Zisserman - 2009 - Taking the bite out of automated naming of characters in TV video.pdf:pdf},
journal = {Image and Vision Computing},
month = apr,
number = {5},
pages = {545--559},
title = {{Taking the bite out of automated naming of characters in TV video}},
volume = {27},
year = {2009}
}
@inproceedings{Cour2010,
author = {Cour, Timothee and Sapp, Benjamin and Nagle, Akash and Taskar, Ben},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cour et al. - 2010 - Talking Pictures Temporal Grouping and Dialog-Supervised Person Recognition.pdf:pdf},
month = may,
number = {2},
publisher = {IEEE},
title = {{Talking Pictures: Temporal Grouping and Dialog-Supervised Person Recognition}},
volume = {2},
year = {2010}
}
@inproceedings{Gilbert2009,
author = {Gilbert, Andrew and Illingworth, John and Bowden, Richard},
booktitle = {ICCV},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gilbert, Illingworth, Bowden - 2009 - Fast Realistic Multi-Action Recognition using Mined Dense Spatio-temporal.pdf:pdf},
title = {{Fast Realistic Multi-Action Recognition using Mined Dense Spatio-temporal}},
year = {2009}
}
@inproceedings{Ramanan2006,
author = {Ramanan, Deva and Sminchisescu, Cristian},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ramanan, Sminchisescu - 2006 - Training Deformable Models for Localization.pdf:pdf},
pages = {206--213},
publisher = {IEEE},
title = {{Training Deformable Models for Localization}},
year = {2006}
}
@inproceedings{Gilbert2008,
abstract = {The use of sparse invariant features to recognise classes of actions or objects has become common in the literature. However, features are often "engineered" to be both sparse and invariant to transformation and it is assumed that they provide the greatest discriminative information. To tackle activity recognition, we propose learning compound features that are assembled from simple 2D corners in both space and time. Each corner is encoded in relation to its neighbours and from an over complete set (in excess of 1 million possible features), compound features are extracted using data mining. The final classifier, consisting of sets of compound features, can then be applied to recognise and localise an activity in real-time while providing superior performance to other state-of-the-art approaches (including those based upon sparse feature detectors). Furthermore, the approach requires only weak supervision in the form of class labels for each training sequence. No ground truth position or temporal alignment is required during training.},
address = {Berlin, Heidelberg},
author = {Gilbert, Andrew and Illingworth, John and Bowden, Richard},
booktitle = {ECCV},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gilbert, Illingworth, Bowden - 2008 - Scale Invariant Action Recognition Using Compound Features Mined from Dense Spatio-temporal Corners.pdf:pdf},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Scale Invariant Action Recognition Using Compound Features Mined from Dense Spatio-temporal Corners}},
volume = {5302},
year = {2008}
}
@article{Fei-Fei2007,
abstract = {What do we see when we glance at a natural scene and how does it change as the glance becomes longer? We asked naive subjects to report in a free-form format what they saw when looking at briefly presented real-life photographs. Our subjects received no specific information as to the content of each stimulus. Thus, our paradigm differs from previous studies where subjects were cued before a picture was presented and/or were probed with multiple-choice questions. In the first stage, 90 novel grayscale photographs were foveally shown to a group of 22 native-English-speaking subjects. The presentation time was chosen at random from a set of seven possible times (from 27 to 500 ms). A perceptual mask followed each photograph immediately. After each presentation, subjects reported what they had just seen as completely and truthfully as possible. In the second stage, another group of naive individuals was instructed to score each of the descriptions produced by the subjects in the first stage. Individual scores were assigned to more than a hundred different attributes. We show that within a single glance, much object- and scene-level information is perceived by human subjects. The richness of our perception, though, seems asymmetrical. Subjects tend to have a propensity toward perceiving natural scenes as being outdoor rather than indoor. The reporting of sensory- or feature-level information of a scene (such as shading and shape) consistently precedes the reporting of the semantic-level information. But once subjects recognize more semantic-level components of a scene, there is little evidence suggesting any bias toward either scene-level or object-level recognition.},
author = {Fei-Fei, Li and Iyer, Asha and Koch, Christof and Perona, Pietro},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fei-Fei et al. - 2007 - What do we perceive in a glance of a real-world scene.pdf:pdf},
journal = {Journal of vision},
keywords = {Adult,Environment,Humans,Observer Variation,Pattern Recognition, Visual,Perceptual Masking,Photography,Time Factors,Visual Perception,Visual Perception: physiology},
month = jan,
number = {1},
pages = {10},
pmid = {17461678},
title = {{What do we perceive in a glance of a real-world scene?}},
volume = {7},
year = {2007}
}
@inproceedings{Wang2009,
author = {Wang, Yang and Mori, Greg},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang, Mori - 2009 - Max-margin hidden conditional random fields for human action recognition.pdf:pdf},
month = jun,
pages = {872--879},
publisher = {IEEE},
title = {{Max-margin hidden conditional random fields for human action recognition}},
year = {2009}
}
@inproceedings{Laptev2007,
author = {Laptev, Ivan and Perez, Patrick},
booktitle = {ICCV},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Laptev, Perez - 2007 - Retrieving actions in movies.pdf:pdf},
month = oct,
pages = {1--8},
publisher = {IEEE},
title = {{Retrieving actions in movies}},
year = {2007}
}
@inproceedings{Tu2003,
author = {Tu, Zhuowen and Chen, Xiangrong and Yuille, Alan L. and Zhu, Song-Chun},
booktitle = {ICCV},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tu et al. - 2003 - Image parsing unifying segmentation, detection, and recognition.pdf:pdf},
number = {2},
pages = {18--25 vol.1},
publisher = {IEEE},
title = {{Image parsing: unifying segmentation, detection, and recognition}},
volume = {63},
year = {2003}
}
@article{Csibra2007a,
address = {Oxford},
author = {Csibra, Gergely},
editor = {Haggard, P. and Rosetti, Y. and Kawato, M.},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Csibra - 2007 - Action mirroring and action understanding An alternative account.pdf:pdf},
journal = {Sensorimotor Foundations of Higher Cognition. Attention and Performance XXII},
pages = {435--459},
publisher = {Oxford University Press},
title = {{Action mirroring and action understanding: An alternative account}},
volume = {22},
year = {2007}
}
@inproceedings{Chum2009,
author = {Chum, Ondrej and Perdoch, Michal and Matas, Jiri},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chum, Perdoch, Matas - 2009 - Geometric min-Hashing Finding a (thick) needle in a haystack.pdf:pdf},
month = jun,
pages = {17--24},
publisher = {IEEE},
title = {{Geometric min-Hashing: Finding a (thick) needle in a haystack}},
year = {2009}
}
@inproceedings{Dalal2005,
author = {Dalal, Navneet and Triggs, Bill},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dalal, Triggs - 2005 - Histograms of Oriented Gradients for Human Detection.pdf:pdf},
pages = {886--893},
publisher = {IEEE},
title = {{Histograms of Oriented Gradients for Human Detection}},
volume = {1},
year = {2005}
}
@article{Han2009,
author = {Han, Bohyung and Zhu, Ying and Comaniciu, Dorin and Davis, Larry S.},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Han et al. - 2009 - Visual tracking by continuous density propagation in sequential bayesian filtering framework..pdf:pdf},
journal = {IEEE TPAMI},
keywords = {Algorithms,Artificial Intelligence,Automated,Automated: methods,Bayes Theorem,Computer-Assisted,Computer-Assisted: methods,Image Enhancement,Image Enhancement: methods,Image Interpretation,Pattern Recognition,Reproducibility of Results,Sensitivity and Specificity,Signal Processing,Subtraction Technique},
month = may,
number = {5},
pages = {919--30},
pmid = {19299864},
title = {{Visual tracking by continuous density propagation in sequential bayesian filtering framework.}},
volume = {31},
year = {2009}
}
@inproceedings{Ryoo2009,
author = {Ryoo, Michael S. and Aggarwal, J. K.},
booktitle = {ICCV},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ryoo, Aggarwal - 2009 - Spatio-Temporal Relationship Match Video Structure Comparison for Recognition of Complex Human Activities.pdf:pdf},
title = {{Spatio-Temporal Relationship Match: Video Structure Comparison for Recognition of Complex Human Activities}},
year = {2009}
}
@inproceedings{Sun2009,
author = {Sun, Ju and Wu, Xiao and Yan, Shuicheng and Cheong, Loong-Fah and Chua, Tat-Seng and Li, Jintao},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sun et al. - 2009 - Hierarchical spatio-temporal context modeling for action recognition.pdf:pdf},
month = jun,
pages = {2004--2011},
publisher = {IEEE},
title = {{Hierarchical spatio-temporal context modeling for action recognition}},
year = {2009}
}
@inproceedings{Jie2009,
author = {Jie, Luo and Caputo, Barbara and Ferrari, Vittorio},
booktitle = {NIPS},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jie, Caputo, Ferrari - 2009 - Who’s Doing What Joint Modeling of Names and Verbs for Simultaneous Face and Pose Annotation.pdf:pdf},
pages = {1--9},
title = {{Who’s Doing What: Joint Modeling of Names and Verbs for Simultaneous Face and Pose Annotation}},
year = {2009}
}
@inproceedings{Gehler2009,
author = {Gehler, Peter Vincent and Nowozin, Sebastian},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gehler, Nowozin - 2009 - Let the kernel figure it out Principled learning of pre-processing for kernel classifiers.pdf:pdf},
month = jun,
pages = {2836--2843},
publisher = {IEEE},
title = {{Let the kernel figure it out; Principled learning of pre-processing for kernel classifiers}},
year = {2009}
}
@inproceedings{Yao2010,
author = {Yao, Bangpeng and Fei-Fei, Li},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yao, Fei-Fei - 2010 - Modeling Mutual Context of Object and Human Pose in Human-Object Interaction Activities.pdf:pdf},
publisher = {IEEE},
title = {{Modeling Mutual Context of Object and Human Pose in Human-Object Interaction Activities}},
year = {2010}
}
@inproceedings{Niebles2006,
author = {Niebles, Juan Carlos and Wang, Hongcheng and Fei-Fei, Li},
booktitle = {BMVC},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Niebles, Wang, Fei-Fei - 2006 - Unsupervised Learning of Human Action Categories Using Spatial-Temporal Words.pdf:pdf},
month = mar,
title = {{Unsupervised Learning of Human Action Categories Using Spatial-Temporal Words}},
year = {2006}
}
@inproceedings{Bouchard2005,
author = {Bouchard, Guillaume and Triggs, Bill},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bouchard, Triggs - 2005 - Hierarchical Part-Based Visual Object Categorization.pdf:pdf},
pages = {710--715},
publisher = {IEEE},
title = {{Hierarchical Part-Based Visual Object Categorization}},
year = {2005}
}
@article{Ikizler2009,
author = {Duygulu, P?nar and Ikizler, Nazli},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Duygulu, Ikizler - 2009 - Histogram of oriented rectangles A new pose descriptor for human action recognition.pdf:pdf},
journal = {Image and Vision Computing},
number = {10},
pages = {1515--1526},
publisher = {Elsevier},
title = {{Histogram of oriented rectangles: A new pose descriptor for human action recognition}},
volume = {27},
year = {2009}
}
@article{Tversky1983,
author = {Tversky, Barbara and Hemenway, Kathleen},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tversky, Hemenway - 1983 - Categories of Environmental Scenes.pdf:pdf},
journal = {Cognitive Psychology},
number = {1},
pages = {121--149},
title = {{Categories of Environmental Scenes}},
volume = {15},
year = {1983}
}
@inproceedings{Kumar2009,
author = {Kumar, Neeraj and Berg, Alexander C. and Belhumeur, Peter N. and Nayar, Shree K.},
booktitle = {ICCV},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kumar et al. - 2009 - Attribute and Simile Classifiers for Face Verification.pdf:pdf},
title = {{Attribute and Simile Classifiers for Face Verification}},
year = {2009}
}
@inproceedings{Niebles2010,
author = {Niebles, Juan Carlos and Han, Bohyung and Fei-Fei, Li},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Niebles, Han, Fei-Fei - 2010 - Efficient Extraction of Human Motion Volumes by Tracking.pdf:pdf},
title = {{Efficient Extraction of Human Motion Volumes by Tracking}},
year = {2010}
}
@inproceedings{Shah2009,
author = {Liu, Jingen and Luo, Jiebo and Shah, Mubarak},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu, Luo, Shah - 2009 - Recognizing realistic actions from videos “in the wild”.pdf:pdf},
month = jun,
pages = {1996--2003},
publisher = {IEEE},
title = {{Recognizing realistic actions from videos “in the wild”}},
year = {2009}
}
@inproceedings{Duchenne2009,
author = {Duchenne, Olivier and Laptev, Ivan and Sivic, Josef and Bach, Francis and Ponce, Jean},
booktitle = {ICCV},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Duchenne et al. - 2009 - Automatic Annotation of Human Actions in Video.pdf:pdf},
number = {Section 3},
title = {{Automatic Annotation of Human Actions in Video}},
year = {2009}
}
@inproceedings{Ramanan2007,
author = {Ramanan, Deva and Baker, Simon and Kakade, Sham},
booktitle = {ICCV},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ramanan, Baker, Kakade - 2007 - Leveraging archival video for building face datasets.pdf:pdf},
pages = {1--8},
publisher = {IEEE},
title = {{Leveraging archival video for building face datasets}},
year = {2007}
}
@inproceedings{Kitani,
author = {Kitani, Kris M. and Sato, Yoichi and Sugimoto, Akihiro},
booktitle = {VSPETS},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kitani, Sato, Sugimoto - 2005 - Deleted Interpolation Using a Hierarchical Bayesian Grammar Network for Recognizing Human Activity.pdf:pdf},
pages = {239--246},
publisher = {IEEE},
title = {{Deleted Interpolation Using a Hierarchical Bayesian Grammar Network for Recognizing Human Activity}},
year = {2005}
}
@inproceedings{Desai2010,
author = {Desai, Chaitanya and Ramanan, Deva and Fowlkes, Charless},
booktitle = {CVPR Workshop},
file = {:home/jniebles/Documents/research/papers//Desai, Ramanan, Fowlkes - 2010 - Discriminative models for static human-object interactions.pdf:pdf},
month = jun,
pages = {9--16},
publisher = {IEEE},
title = {{Discriminative models for static human-object interactions}},
year = {2010}
}
@article{Song2003,
author = {Song, Yang and Goncalves, Luis and Perona, Pietro},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Song, Goncalves, Perona - 2003 - Unsupervised learning of human motion.pdf:pdf},
journal = {TPAMI},
number = {7},
pages = {814--827},
title = {{Unsupervised learning of human motion}},
volume = {25},
year = {2003}
}
@article{Yang2008a,
author = {Yang, Rongqian and Cheng, Sheng and Yang, Wei and Chen, Yazhu},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang et al. - 2008 - Robust and Accurate Surface Measurement Using Structured Light.pdf:pdf},
journal = {Instrumentation},
number = {6},
pages = {1275--1280},
title = {{Robust and Accurate Surface Measurement Using Structured Light}},
volume = {57},
year = {2008}
}
@inproceedings{Lucas1981,
author = {Lucas, Bruce D. and Kanade, Takeo},
booktitle = {International Joint Conference on Artificial Intelligence},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lucas, Kanade - 1981 - An Iterative Image Registration Technique with an Application to Stereo Vision.pdf:pdf},
pages = {674--679},
title = {{An Iterative Image Registration Technique with an Application to Stereo Vision}},
volume = {3},
year = {1981}
}
@inproceedings{Zhong2004,
author = {Zhong, Hua and Shi, Jianbo and Visontai, Mirko},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhong, Shi, Visontai - 2004 - Detecting unusual activity in video.pdf:pdf},
pages = {819--826},
publisher = {IEEE},
title = {{Detecting unusual activity in video}},
volume = {2},
year = {2004}
}
@article{Zacks2007,
author = {Zacks, Jeffrey M. and Swallow, Khena M.},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zacks, Swallow - 2007 - Event Segmentation.pdf:pdf},
journal = {Current Directions in Psychological Science},
keywords = {event,in-,motion,perception,segmentation},
month = apr,
number = {2},
pages = {80--84},
title = {{Event Segmentation}},
volume = {16},
year = {2007}
}
@article{Baker2004,
author = {Baker, Simon and Matthews, Iain},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Baker, Matthews - 2004 - Lucas-Kanade 20 Years On A Unifying Framework.pdf:pdf},
journal = {IJCV},
number = {3},
pages = {221--255},
title = {{Lucas-Kanade 20 Years On: A Unifying Framework}},
volume = {56},
year = {2004}
}
@inproceedings{Feng2002,
abstract = {An algorithm for the recognition of human actions in image sequences is presented. The algorithm consists of 3 stages: background subtraction, body pose classification, and action recognition. A pose is represented in space-time, called 'movelet'. A movelet is a collection of the shape, motion and occlusion of image patches corresponding to the main parts of the body. The (infinite) set of all possible movelets is quantized into codewords obtained by the vector quantization. For every pair of frames each codeword is assigned a probability. Recognition is performed by simultaneously estimating the most likely sequence of codewords and the action that took place in a sequence. This is done using hidden Markov models. Experiments on the recognition of 3 periodic human actions, each under 3 different viewpoints, and 8 non-periodic human actions, are presented. training and testing are performed on different subjects with encouraging results. The influence of the number of codewords on the algorithm performance is studied.},
author = {Feng, Xiaolin and Perona, Pietro},
booktitle = {3DPVT},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Feng, Perona - 2002 - Human action recognition by sequence of movelet codewords.pdf:pdf},
pages = {717--721},
publisher = {IEEE},
title = {{Human action recognition by sequence of movelet codewords}},
volume = {16},
year = {2002}
}
@inproceedings{Xia2012,
author = {Xia, Lu and Chen, Chia-Chih and Aggarwal, J. K.},
booktitle = {CVPR Workshop},
title = {View Invariant Human Action Recognition Using Histograms of {3D} Joints},
year = {2012}
}
@inproceedings{Fathi2008,
author = {Fathi, Alireza and Mori, Greg},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fathi, Mori - 2008 - Action recognition by learning mid-level motion features.pdf:pdf},
month = jun,
pages = {1--8},
publisher = {IEEE},
title = {{Action recognition by learning mid-level motion features}},
year = {2008}
}
@inproceedings{Bennett2004,
author = {Bennett, Brandon and Magee, Derek R. and Cohn, Anthony G. and Hogg, David C.},
booktitle = {ECAI},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bennett et al. - 2004 - Using Spatio-Temporal Continuity Constraints to Enhance Visual Tracking of Moving Objects.pdf:pdf},
title = {{Using Spatio-Temporal Continuity Constraints to Enhance Visual Tracking of Moving Objects}},
year = {2004}
}
@inproceedings{Rapantzikos2009,
author = {Rapantzikos, Konstantinos and Avrithis, Yannis and Kollias, Stefanos},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rapantzikos, Avrithis, Kollias - 2009 - Dense saliency-based spatiotemporal feature points for action recognition.pdf:pdf},
month = jun,
pages = {1454--1461},
publisher = {IEEE},
title = {{Dense saliency-based spatiotemporal feature points for action recognition}},
year = {2009}
}
@inproceedings{Tuzel2007,
abstract = {We present a new algorithm to detect humans in still images utilizing covariance matrices as object descriptors. Since these descriptors do not lie on a vector space, well known machine learning techniques are not adequate to learn the classifiers. The space of d-dimensional nonsingular covariance matrices can be represented as a connected Riemannian manifold. We present a novel approach for classifying points lying on a Riemannian manifold by incorporating the a priori information about the geometry of the space. The algorithm is tested on INRIA human database where superior detection rates are observed over the previous approaches.},
author = {Tuzel, Oncel and Porikli, Fatih and Meer, Peter},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tuzel, Porikli, Meer - 2007 - Human Detection via Classification on Riemannian Manifolds.pdf:pdf},
pages = {1--8},
publisher = {IEEE},
title = {{Human Detection via Classification on Riemannian Manifolds}},
year = {2007}
}
@article{Shi,
author = {Shi, Boxin and Matsushita, Yasuyuki},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shi, Matsushita - Unknown - Self-calibrating Photometric Stereo.pdf:pdf},
journal = {Computer},
title = {{Self-calibrating Photometric Stereo}}
}
@inproceedings{Ferrari2008,
author = {Ferrari, Vittorio and Marin-Jimenez, Manuel and Zisserman, Andrew},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ferrari, Marin-Jimenez, Zisserman - 2008 - Progressive search space reduction for human pose estimation.pdf:pdf},
pages = {1--8},
publisher = {IEEE},
title = {{Progressive search space reduction for human pose estimation}},
year = {2008}
}
@inproceedings{Li2007,
author = {Li, Li-jia and Niebles, Juan Carlos and Fei-Fei, Li},
booktitle = {AAAI},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li, Niebles, Fei-Fei - 2007 - OPTIMOL A Framework for Online Picture Collection via Incremental Model Learning.pdf:pdf},
pages = {1987--1988},
title = {{OPTIMOL: A Framework for Online Picture Collection via Incremental Model Learning}},
year = {2007}
}
@inproceedings{Brendel2009,
author = {Brendel, William and Todorovic, Sinisa},
booktitle = {ICCV},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Brendel, Todorovic - 2009 - Video object segmentation by tracking regions.pdf:pdf},
month = sep,
pages = {833--840},
publisher = {IEEE},
title = {Video object segmentation by tracking regions},
year = {2009}
}
@article{Blake2007,
abstract = {Humans, being highly social creatures, rely heavily on the ability to perceive what others are doing and to infer from gestures and expressions what others may be intending to do. These perceptual skills are easily mastered by most, but not all, people, in large part because human action readily communicates intentions and feelings. In recent years, remarkable advances have been made in our understanding of the visual, motoric, and affective influences on perception of human action, as well as in the elucidation of the neural concomitants of perception of human action. This article reviews those advances and, where possible, draws links among those findings.},
author = {Blake, Randolph and Shiffrar, Maggie},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Blake, Shiffrar - 2007 - Perception of human motion.pdf:pdf},
journal = {Annual review of psychology},
keywords = {Animals,Biomechanics,Brain Mapping,Cerebral,Cerebral: physiology,Computer-Assisted,Dominance,Form Perception,Form Perception: physiology,Humans,Image Processing,Imaging,Magnetic Resonance Imaging,Motion Perception,Motion Perception: physiology,Motor Cortex,Motor Cortex: physiopathology,Neurons,Neurons: physiology,Orientation,Orientation: physiology,Parietal Lobe,Parietal Lobe: physiopathology,Perceptual Disorders,Perceptual Disorders: physiopathology,Personal Construct Theory,Temporal Lobe,Temporal Lobe: physiology,Three-Dimensional,Walking,Walking: physiology},
pages = {47--73},
pmid = {16903802},
title = {{Perception of human motion}},
volume = {58},
year = {2007}
}
@inproceedings{Eichner2009,
author = {Eichner, Marcin and Ferrari, Vittorio},
booktitle = {BMVC},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Eichner, Ferrari - 2009 - Better appearance models for pictorial structures.pdf:pdf},
pages = {1--11},
title = {{Better appearance models for pictorial structures}},
year = {2009}
}
@phdthesis{Damen2009a,
author = {Damen, Dima},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Damen - 2009 - Activity Analysis Finding Explanations for Sets of Events.pdf:pdf},
school = {The University of Leeds},
title = {{Activity Analysis: Finding Explanations for Sets of Events}},
year = {2009}
}
@inproceedings{Wang,
author = {Wang, Gang and Gallagher, Andrew and Luo, Jiebo},
booktitle = {ECCV},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - Unknown - Seeing People in Social Context Recognizing People and Social Relationships.pdf:pdf},
title = {{Seeing people in social context: Recognizing people and social relationships}},
year = {2010}
}
@article{Chen2010a,
abstract = {Estimating 3D pose similarity is a fundamental problem on 3D motion data. Most previous work calculates \$L2\$-like distance of joint orientations or coordinates, which does not sufficiently reflect the pose similarity of human perception. In this paper we present a new pose distance metric. First, we propose a new rich pose feature set called $\backslash$emph\{Geometric Pose Descriptor\} ($\backslash$emph\{GPD\}). GPD is more effective in encoding pose similarity by utilizing features on geometric relations among body parts, as well as temporal information such as velocities and accelerations. Based on GPD, we propose a semi-supervised distance metric learning algorithm called $\backslash$emph\{Regularized Distance Metric Learning with Sparse Representation\} ($\backslash$emph\{RDSR\}), which integrates information from both unsupervised data relationship and labels. We apply the proposed pose distance metric to applications of motion transition decision and content based pose retrieval. Quantitative evaluations demonstrate that our method achieves better results with only a small amount of human labels, showing that the proposed pose distance metric is a promising building block for various 3D motion related applications.},
author = {Chen, Cheng and Zhuang, Yueting and Nie, Feiping and Yang, Yi and Wu, Fei and Xiao, Jun},
file = {:home/jniebles/Downloads/05674036.pdf:pdf},
journal = {IEEE TVCG},
month = dec,
number = {11},
pages = {1676--1689},
pmid = {21173458},
title = {{Learning a 3D Human Pose Distance Metric from Geometric Pose Descriptor.}},
volume = {17},
year = {2010}
}
@article{Yang2011,
abstract = {Two-dimensional infrared thermography (IRT) is widely used in various domains and can be extended to more applications if the spatial information of the temperature distribution is provided to form three-dimensional (3-D) thermography. A 3-D infrared (IR) imaging system based on structured light is designed to acquire the 3-D surface temperature distribution. The projector, color camera, and IR camera must be geometrically calibrated. However, few studies have been conducted on this topic, and conventional calibration techniques cannot be directly applied to such calibration because the IR camera is sensitive only to thermal information and cannot capture visible calibration patterns. Hence, three calibration patterns are designed, and corresponding calibration methods are proposed to calibrate this system effectively and accurately. Experimental results show that this system has high spatial accuracy and can effectively obtain the temperature distribution of a 3-D surface.},
author = {Yang, Rongqian and Chen, Yazhu},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang, Chen - 2011 - Design of a 3-D Infrared Imaging System Using Structured Light(2).pdf:pdf},
journal = {IEEE Transactions on Instrumentation and Measurement},
month = feb,
number = {2},
pages = {608--617},
title = {{Design of a 3-D Infrared Imaging System Using Structured Light}},
volume = {60},
year = {2011}
}
@article{Lu2009,
author = {Lu, Wei Lwun and Okuma, Kenji and Little, James J},
journal = {Image and Vision Computing},
number = {1--2},
pages = {189--205},
title = {{Tracking and Recognizing Actions of Multiple Hockey Players using the Boosted Particle Filter}},
volume = {27},
year = {2009}
}
@article{Grill-Spector1999,
abstract = {The invariant properties of human cortical neurons cannot be studied directly by fMRI due to its limited spatial resolution. Here, we circumvented this limitation by using fMR adaptation, namely, reduction of the fMR signal due to repeated presentation of identical images. Object-selective regions (lateral occipital complex [LOC]) showed a monotonic signal decrease as repetition frequency increased. The invariant properties of fMR adaptation were studied by presenting the same object in different viewing conditions. LOC exhibited stronger fMR adaptation to changes in size and position (more invariance) compared to illumination and viewpoint. The effect revealed two putative subdivisions within LOC: caudal-dorsal (LO), which exhibited substantial recovery from adaptation under all transformations, and posterior fusiform (PF/LOa), which displayed stronger adaptation. This study demonstrates the utility of fMR adaptation for revealing functional characteristics of neurons in fMRI studies.},
author = {Grill-Spector, Kalanit and Kushnir, Tammar and Edelman, Shimon and Avidan, Galia and Itzchak, Yacov and Malach, Rafael},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Grill-Spector et al. - 1999 - Differential processing of objects under various viewing conditions in the human lateral occipital complex.pdf:pdf},
journal = {Neuron},
keywords = {Adaptation,Adult,Automobiles,Face,Female,Humans,Light,Magnetic Resonance Imaging,Male,Middle Aged,Occipital Lobe,Occipital Lobe: physiology,Physiological,Rotation,Time Factors,Visual Perception,Visual Perception: physiology},
month = sep,
number = {1},
pages = {187--203},
pmid = {10677037},
title = {{Differential processing of objects under various viewing conditions in the human lateral occipital complex}},
volume = {24},
year = {1999}
}
@article{Birchfield2008,
author = {Birchfield, Stanley T. and Pundlik, Shrinivas J.},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Birchfield, Pundlik - 2008 - Joint tracking of features and edges.pdf:pdf},
journal = {CVPR},
month = jun,
pages = {1--6},
publisher = {Ieee},
title = {{Joint tracking of features and edges}},
year = {2008}
}
@inproceedings{Mikolajczyk2008,
author = {Mikolajczyk, Krystian and Uemura, Hirofumi},
booktitle = {CVPR},
month = jun,
pages = {1--8},
publisher = {IEEE},
title = {{Action recognition with motion-appearance vocabulary forest}},
year = {2008}
}
@inproceedings{Yao2010a,
author = {Yao, Angela and Gall, Juergen and {Van Gool}, Luc},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yao, Gall, Van Gool - 2010 - A Hough transform-based voting framework for action recognition.pdf:pdf},
month = jun,
pages = {2061--2068},
publisher = {IEEE},
title = {{A Hough transform-based voting framework for action recognition}},
year = {2010}
}
@inproceedings{Klein2002,
author = {Klein, Dan and Kamvar, Sepandar D. and Manning, Christopher D.},
booktitle = {ICML},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Klein, Kamvar, Manning - 2002 - From instance-level constraints to space-level constraints Making the most of prior knowledge in data clustering.pdf:pdf},
pages = {307--314},
title = {{From instance-level constraints to space-level constraints: Making the most of prior knowledge in data clustering}},
year = {2002}
}
@inproceedings{Andriluka2008,
author = {Andriluka, Mykhaylo and Roth, Stefan and Schiele, Bernt},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Andriluka, Roth, Schiele - 2008 - People-tracking-by-detection and people-detection-by-tracking.pdf:pdf},
month = jun,
pages = {1--8},
publisher = {IEEE},
title = {{People-tracking-by-detection and people-detection-by-tracking}},
year = {2008}
}
@techreport{Barriuso2012,
author = {Barriuso, Adela and Torralba, Antonio},
institution = {MIT},
title = {{Notes on image annotation}},
year = {2012}
}
@inproceedings{Ramanan2003,
author = {Ramanan, Deva and Forsyth, David A.},
booktitle = {NIPS},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ramanan, Forsyth - 2003 - Automatic annotation of everyday movements.pdf:pdf},
title = {{Automatic annotation of everyday movements}},
year = {2003}
}
@inproceedings{Ramanan2009,
author = {Ramanan, Deva and Baker, Simon},
booktitle = {ICCV},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ramanan, Baker - 2009 - Local Distance Functions A Taxonomy, New Algorithms, and an Evaluation.pdf:pdf},
title = {{Local Distance Functions: A Taxonomy, New Algorithms, and an Evaluation}},
year = {2009}
}
@inproceedings{Wang2006,
author = {Wang, Yang and Jiang, Hao and Drew, Mark S. and Li, Ze-Nian and Mori, Greg},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2006 - Unsupervised Discovery of Action Classes.pdf:pdf},
pages = {1654--1661},
publisher = {IEEE},
title = {{Unsupervised Discovery of Action Classes}},
year = {2006}
}
@inproceedings{Rodriguez2008,
author = {Rodriguez, Mikel D. and Ahmed, Javed and Shah, Mubarak},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rodriguez, Ahmed, Shah - 2008 - Action MACH A Spatio-temporal Maximum Average Correlation Height Filter for Action Recognition.pdf:pdf},
month = jun,
pages = {1--8},
publisher = {IEEE},
title = {{Action MACH: A Spatio-temporal Maximum Average Correlation Height Filter for Action Recognition}},
year = {2008}
}
@article{Zacks2001,
abstract = {Temporal structure has a major role in human understanding of everyday events. Observers are able to segment ongoing activity into temporal parts and sub-parts that are reliable, meaningful and correlated with ecologically relevant features of the action. Here we present evidence that a network of brain regions is tuned to perceptually salient event boundaries, both during intentional event segmentation and during naive passive viewing of events. Activity within this network may provide a basis for parsing the temporally evolving environment into meaningful units.},
author = {Zacks, Jeffrey M. and Braver, Todd S. and Sheridan, Margaret A. and Donaldson, David I. and Snyder, Abraham Z. and Ollinger, John M. and Buckner, Randy L. and Raichle, Marcus E.},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zacks et al. - 2001 - Human brain activity time-locked to perceptual event boundaries.pdf:pdf},
journal = {Nature neuroscience},
keywords = {Adolescent,Adult,Analysis of Variance,Brain,Brain Mapping,Brain: physiology,Cerebral Cortex,Cerebral Cortex: physiology,Female,Functional Laterality,Housekeeping,Humans,Magnetic Resonance Imaging,Male,Middle Aged,Motion Pictures as Topic,Neocortex,Neocortex: physiology,Time Factors,Visual Perception,Visual Perception: physiology},
month = jun,
number = {6},
pages = {651--5},
pmid = {11369948},
title = {{Human brain activity time-locked to perceptual event boundaries}},
volume = {4},
year = {2001}
}
@inproceedings{Yao2009,
author = {Yao, Bangpeng and Niebles, Juan Carlos and Fei-Fei, Li},
booktitle = {CVPR Workshop},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yao, Niebles, Fei-Fei - 2009 - Mining discriminative adjectives and prepositions for natural scene recognition.pdf:pdf},
month = jun,
pages = {100--106},
publisher = {IEEE},
title = {{Mining discriminative adjectives and prepositions for natural scene recognition}},
volume = {1},
year = {2009}
}
@inproceedings{Lin2009,
author = {Lin, Zhe and Jiang, Zhuolin and Davis, Larry S.},
booktitle = {ICCV},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lin, Jiang, Davis - 2009 - Recognizing actions by shape-motion prototype trees.pdf:pdf},
month = sep,
pages = {444--451},
publisher = {IEEE},
title = {{Recognizing actions by shape-motion prototype trees}},
year = {2009}
}
@inproceedings{Dalal2006,
author = {Dalal, Navneet and Triggs, Bill and Schmid, Cordelia},
booktitle = {ECCV},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dalal, Triggs, Schmid - 2006 - Human Detection Using Oriented Histograms of Flow and Appearance.pdf:pdf},
pages = {428--441},
title = {{Human Detection Using Oriented Histograms of Flow and Appearance}},
year = {2006}
}
@inproceedings{Wojek2009,
author = {Wojek, Christian and Walk, Stefan and Schiele, Bernt},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wojek, Walk, Schiele - 2009 - Multi-cue onboard pedestrian detection.pdf:pdf},
month = jun,
pages = {794--801},
publisher = {IEEE},
title = {{Multi-cue onboard pedestrian detection}},
year = {2009}
}
@article{Biederman1982,
author = {Biederman, Irving and Mezzanotte, Robert J. and Rabinowitz, Jan C.},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Biederman, Mezzanotte, Rabinowitz - 1982 - Scene perception detecting and judging objects undergoing relational violations.pdf:pdf},
journal = {Cognitive psychology},
keywords = {Cognition,Discrimination Learning,Form Perception,Humans,Reaction Time,Semantics},
month = apr,
number = {2},
pages = {143--77},
pmid = {7083801},
title = {{Scene perception: detecting and judging objects undergoing relational violations}},
volume = {14},
year = {1982}
}
@inproceedings{Wang2009c,
author = {Wang, Ping and Abowd, Gregory D. and Rehg, James M.},
booktitle = {ICCV},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang, Abowd, Rehg - 2009 - Quasi-Periodic Event Analysis for Social Game Retrieval.pdf:pdf},
title = {{Quasi-Periodic Event Analysis for Social Game Retrieval}},
year = {2009}
}
@inproceedings{Li2009,
author = {Li, Li-Jia and Socher, Richard and Fei-Fei, Li},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li, Socher, Fei-Fei - 2009 - Towards total scene understanding Classification, annotation and segmentation in an automatic framework.pdf:pdf},
month = jun,
pages = {2036--2043},
publisher = {IEEE},
title = {{Towards total scene understanding: Classification, annotation and segmentation in an automatic framework}},
year = {2009}
}
@inproceedings{Felzenszwalb2010,
address = {San Francisco},
author = {Felzenszwalb, Pedro F. and Girshick, Ross B. and McAllester, David},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Felzenszwalb, Girshick, McAllester - 2010 - Cascade Object Detection with Deformable Part Models.pdf:pdf},
publisher = {IEEE},
title = {{Cascade Object Detection with Deformable Part Models}},
year = {2010}
}
@inproceedings{Yilmaz2005,
author = {Yilmaz, Alper and Shah, Mubarak},
booktitle = {ICCV},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yilmaz, Shah - 2005 - Recognizing Human Actions in Videos Acquired by Uncalibrated Moving Cameras.pdf:pdf},
pages = {150--157},
publisher = {IEEE},
title = {{Recognizing Human Actions in Videos Acquired by Uncalibrated Moving Cameras}},
volume = {1},
year = {2005}
}
@inproceedings{Sadeghi2011a,
author = {Sadeghi, Mohammad Amin and Farhadi, Ali},
booktitle = {CVPR},
month = jun,
pages = {1745--1752},
publisher = {IEEE},
title = {{Recognition using visual phrases}},
year = {2011}
}
@article{Blei2003,
author = {Blei, David M. and Ng, Andrew Y. and Jordan, Michael I.},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Blei, Ng, Jordan - 2003 - Latent dirichlet allocation.pdf:pdf},
journal = {JMLR},
pages = {993--1022},
publisher = {MIT Press Cambridge, MA, USA},
title = {{Latent dirichlet allocation}},
volume = {3},
year = {2003}
}
@inproceedings{Kim2007,
abstract = {We introduce a new framework, namely tensor canonical correlation analysis (TCCA) which is an extension of classical canonical correlation analysis (CCA) to multidimensional data arrays (or tensors) and apply this for action/gesture classification in videos. By tensor CCA, joint space-time linear relationships of two video volumes are inspected to yield flexible and descriptive similarity features of the two videos. The TCCA features are combined with a discriminative feature selection scheme and a nearest neighbor classifier for action classification. In addition, we propose a time-efficient action detection method based on dynamic learning of subspaces for tensor CCA for the case that actions are not aligned in the space-time domain. The proposed method delivered significantly better accuracy and comparable detection speed over state-of-the-art methods on the KTH action data set as well as self-recorded hand gesture data sets.},
author = {Kim, Tae-Kyun and Wong, Shu-Fai and Cipolla, Roberto},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kim, Wong, Cipolla - 2007 - Tensor Canonical Correlation Analysis for Action Classification.pdf:pdf},
pages = {1--8},
publisher = {IEEE},
title = {{Tensor Canonical Correlation Analysis for Action Classification}},
year = {2007}
}
@article{Schmid2000,
author = {Schmid, Cordelia and Mohr, Roger and Bauckhage, Christian},
journal = {IJCV},
number = {2},
pages = {151--172},
title = {{Evaluation of Interest Point Detectors}},
volume = {37},
year = {2000}
}
@inproceedings{Jin2009,
author = {Jin, Xin and Kim, Sangkyum and Han, Jiawei and Cao, Li and Yin, Zhijun},
booktitle = {SDM},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jin et al. - 2009 - GAD General Activity Detection for Fast Clustering on Large Data.pdf:pdf},
title = {{GAD: General Activity Detection for Fast Clustering on Large Data}},
year = {2009}
}
@inproceedings{Ke2005,
author = {Ke, Yan and Sukthankar, Rahul and Hebert, Martial},
booktitle = {ICCV},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ke, Sukthankar, Hebert - 2005 - Efficient Visual Event Detection Using Volumetric Features.pdf:pdf},
pages = {166--173},
publisher = {IEEE},
title = {{Efficient Visual Event Detection Using Volumetric Features}},
volume = {1},
year = {2005}
}
@inproceedings{Ke2007,
author = {Ke, Yan and Sukthankar, Rahul and Hebert, Martial},
booktitle = {ICCV},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ke, Sukthankar, Hebert - 2007 - Event Detection in Crowded Videos.pdf:pdf},
month = oct,
pages = {1--8},
publisher = {IEEE},
title = {{Event Detection in Crowded Videos}},
year = {2007}
}
@inproceedings{Stone2008,
author = {Stone, Zak and Zickler, Todd and Darrell, Trevor},
booktitle = {CVPR Workshop},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Stone, Zickler, Darrell - 2008 - Autotagging Facebook Social network context improves photo annotation.pdf:pdf},
month = jun,
pages = {1--8},
publisher = {IEEE},
title = {{Autotagging Facebook: Social network context improves photo annotation}},
year = {2008}
}
@inproceedings{Niebles2010a,
author = {Niebles, Juan Carlos and Chen, Chih-Wei and Fei-Fei, Li},
booktitle = {ECCV},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Niebles, Chen, Fei-Fei - 2010 - Modeling Temporal Structure of Decomposable Motion Segments for Activity Classification.pdf:pdf},
keywords = {activity recognition,discriminative classifiers},
title = {Modeling Temporal Structure of Decomposable Motion Segments for Activity Classification},
year = {2010}
}
@inproceedings{Laptev2008,
author = {Laptev, Ivan and Marszalek, Marcin and Schmid, Cordelia and Rozenfeld, Benjamin},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Laptev et al. - 2008 - Learning realistic human actions from movies.pdf:pdf},
title = {{Learning realistic human actions from movies}},
year = {2008}
}
@inproceedings{Tran2008,
author = {Tran, Du and Sorokin, Alexander},
booktitle = {ECCV},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tran, Sorokin - 2008 - Human activity recognition with metric learning.pdf:pdf},
pages = {561},
publisher = {Springer-Verlag},
title = {{Human activity recognition with metric learning}},
year = {2008}
}
@inproceedings{Felzenszwalb2008,
author = {Felzenszwalb, Pedro F. and McAllester, David and Ramanan, Deva},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Felzenszwalb, McAllester, Ramanan - 2008 - A discriminatively trained, multiscale, deformable part model.pdf:pdf},
month = jun,
pages = {1--8},
publisher = {IEEE},
title = {{A discriminatively trained, multiscale, deformable part model}},
year = {2008}
}
@inproceedings{Sivic2006,
author = {Sivic, Josef and Zitnick, C. Lawrence and Szeliski, Richard},
booktitle = {BMVC},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sivic, Zitnick, Szeliski - 2006 - Finding people in repeated shots of the same scene.pdf:pdf},
pages = {909--918},
title = {{Finding people in repeated shots of the same scene}},
year = {2006}
}
@inproceedings{Efros2003,
author = {Efros, Alexei A. and Berg, Alexander C. and Mori, Greg and Malik, Jitendra},
booktitle = {ICCV},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Efros et al. - 2003 - Recognizing action at a distance.pdf:pdf},
pages = {726--733 vol.2},
publisher = {IEEE},
title = {{Recognizing action at a distance}},
volume = {2},
year = {2003}
}
@inproceedings{Yagnik2008,
author = {Yagnik, Jay and Adam, Hartwig and Bau, David},
booktitle = {FG08},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yagnik, Adam, Bau - 2008 - Large scale learning and recognition of faces in web videos.pdf:pdf},
month = sep,
number = {1},
pages = {1--7},
publisher = {IEEE},
title = {{Large scale learning and recognition of faces in web videos}},
year = {2008}
}
@inproceedings{Savarese2008,
author = {Savarese, Silvio and DelPozo, Andrey and Niebles, Juan Carlos and Fei-Fei, Li},
booktitle = {WMVC},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Savarese et al. - 2008 - Spatial-Temporal correlatons for unsupervised action classification.pdf:pdf},
month = jan,
pages = {1--8},
publisher = {IEEE},
title = {{Spatial-Temporal correlatons for unsupervised action classification}},
year = {2008}
}
@inproceedings{Xu2004,
author = {Xu, Linli and Neufeld, James and Larson, Bryce and Schuurmans, Dale},
booktitle = {NIPS},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xu et al. - 2004 - Maximum margin clustering.pdf:pdf},
title = {{Maximum margin clustering}},
year = {2004}
}
@inproceedings{Yu2009,
author = {Yu, Ting and Lim, Ser-Nam and Kedar, Patwardhan and Krahnstoever, Nil},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yu et al. - 2009 - Monitoring, Recognizing and Discovering Social Networks.pdf:pdf},
month = jun,
pages = {1462--1469},
publisher = {IEEE},
title = {{Monitoring, Recognizing and Discovering Social Networks}},
year = {2009}
}
@article{Parameswaran2006,
abstract = {This paper presents an approach for viewpoint invariant human action recognition, an area that has received scant attention so far, relative to the overall body of work in human action recognition. It has been established previously that there exist no invariants for 3D to 2D projection. However, there exist a wealth of techniques in 2D invariance that can be used to advantage in 3D to 2D projection. We exploit these techniques and model actions in terms of view-invariant canonical body poses and trajectories in 2D invariance space, leading to a simple and effective way to represent and recognize human actions from a general viewpoint. We first evaluate the approach theoretically and show why a straightforward application of the 2D invariance idea will not work. We describe strategies designed to overcome inherent problems in the straightforward approach and outline the recognition algorithm. We then present results on 2D projections of publicly available human motion capture data as well on manually segmented real image sequences. In addition to robustness to viewpoint change, the approach is robust enough to handle different people, minor variabilities in a given action, and the speed of aciton (and hence, frame-rate) while encoding sufficient distinction among actions.},
author = {Parameswaran, Vasu and Chellappa, Rama},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Parameswaran, Chellappa - 2006 - View Invariance for Human Action Recognition.pdf:pdf},
journal = {IJCV},
number = {1},
pages = {83--101},
title = {{View Invariance for Human Action Recognition}},
volume = {66},
year = {2006}
}
@inproceedings{Higo2010,
author = {Higo, Tomoaki and Matsushita, Yasuyuki and Ikeuchi, Katsushi},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Higo - Unknown - Consensus Photometric Stereo.pdf:pdf},
title = {{Consensus photometric stereo}},
year = {2010}
}
@inproceedings{Stark2009,
author = {Stark, Michael and Goesele, Michael and Schiele, Bernt},
booktitle = {ICCV},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Stark, Goesele, Schiele - 2009 - A shape-based object class model for knowledge transfer.pdf:pdf},
month = sep,
pages = {373--380},
publisher = {IEEE},
title = {{A shape-based object class model for knowledge transfer}},
year = {2009}
}
@inproceedings{Fulkerson2008a,
author = {Fulkerson, Brian and Vedaldi, Andrea and Soatto, Stefano},
booktitle = {ECCV},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fulkerson, Vedaldi, Soatto - 2008 - Localizing Objects with Smart Dictionaries.pdf:pdf},
pages = {179--192},
title = {{Localizing Objects with Smart Dictionaries}},
year = {2008}
}
@article{Oliva2007,
abstract = {In the real world, objects never occur in isolation; they co-vary with other objects and particular environments, providing a rich source of contextual associations to be exploited by the visual system. A natural way of representing the context of an object is in terms of its relationship to other objects. Alternately, recent work has shown that a statistical summary of the scene provides a complementary and effective source of information for contextual inference, which enables humans to quickly guide their attention and eyes to regions of interest in natural scenes. A better understanding of how humans build such scene representations, and of the mechanisms of contextual analysis, will lead to a new generation of computer vision systems.},
author = {Oliva, Aude and Torralba, Antonio},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Oliva, Torralba - 2007 - The role of context in object recognition.pdf:pdf},
journal = {Trends in cognitive sciences},
keywords = {Animals,Attention,Attention: physiology,Eye Movements,Eye Movements: physiology,Humans,Pattern Recognition,Photic Stimulation,Recognition (Psychology),Visual,Visual: physiology},
number = {12},
pages = {520--7},
pmid = {18024143},
title = {{The role of context in object recognition}},
volume = {11},
year = {2007}
}
@inproceedings{Bourdev2009,
author = {Bourdev, Lubomir and Malik, Jitendra},
booktitle = {ICCV},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bourdev, Malik - 2009 - Poselets Body Part Detectors Trained Using 3D Human Pose Annotations.pdf:pdf},
title = {Poselets: Body Part Detectors Trained Using {3D} Human Pose Annotations},
year = {2009}
}
@inproceedings{Brendel2010,
author = {Brendel, William and Todorovic, Sinisa},
booktitle = {ECCV},
title = {Activities as Time Series of Human Postures},
year = {2010}
}
@article{Yang2008,
author = {Yang, Rongqian and Cheng, Sheng and Chen, Yazhu},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang, Cheng, Chen - 2008 - Flexible and accurate implementation of a binocular structured light system.pdf:pdf},
journal = {Optics and Lasers in Engineering},
keywords = {3d,binocular system,calibration,structured light,surface measurement,three-dimensional},
month = may,
number = {5},
pages = {373--379},
title = {{Flexible and accurate implementation of a binocular structured light system}},
volume = {46},
year = {2008}
}
@inproceedings{Liu2008,
author = {Liu, Jingen and Ali, Saad and Shah, Mubarak},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu, Ali, Shah - 2008 - Recognizing human actions using multiple features.pdf:pdf},
publisher = {IEEE},
title = {{Recognizing human actions using multiple features}},
year = {2008}
}
@inproceedings{Wang2012,
author = {Wang, Jiang and Liu, Zicheng and Wu, Ying and Yuan, Junsong},
booktitle = {CVPR},
title = {Mining Actionlet Ensemble for Action Recognition with Depth Cameras},
year = {2012}
}
@inproceedings{Gupta2009,
author = {Gupta, Abhinav and Srinivasan, Praveen and Shi, Jianbo and Davis, Larry S.},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gupta et al. - 2009 - Understanding videos, constructing plots learning a visually grounded storyline model from annotated videos.pdf:pdf},
month = jun,
pages = {2012--2019},
publisher = {IEEE},
title = {{Understanding videos, constructing plots learning a visually grounded storyline model from annotated videos}},
year = {2009}
}
@inproceedings{Messing2009,
author = {Messing, Ross and Pal, Chris and Kautz, Henry},
booktitle = {ICCV},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Messing, Pal, Kautz - 2009 - Activity recognition using the velocity histories of tracked keypoints.pdf:pdf},
title = {{Activity recognition using the velocity histories of tracked keypoints}},
year = {2009}
}
@inproceedings{Torralba2011,
author = {Torralba, Antonio and Efros, Alexei A.},
booktitle = {CVPR},
month = jun,
pages = {1521--1528},
publisher = {IEEE},
title = {{Unbiased look at dataset bias}},
year = {2011}
}
@article{Felzenszwalb2009,
author = {Felzenszwalb, Pedro F. and Girshick, Ross B. and McAllester, David and Ramanan, Deva},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Felzenszwalb et al. - 2009 - Object Detection with Discriminatively Trained Part Based Models.pdf:pdf},
journal = {IEEE TPAMI},
pages = {1--20},
title = {{Object Detection with Discriminatively Trained Part Based Models}},
year = {2009}
}
@inproceedings{Boiman2005,
abstract = {We address the problem of detecting irregularities in visual data, e.g., detecting suspicious behaviors in video sequences, or identifying salient patterns in images. The term "irregular" depends on the context in which the "regular" or "valid" are defined. Yet, it is not realistic to expect explicit definition of all possible valid configurations for a given context. We pose the problem of determining the validity of visual data as a process of constructing a puzzle: We try to compose a new observed image region or a new video segment ("the query") using chunks of data ("pieces of puzzle") extracted from previous visual examples ("the database "). Regions in the observed data which can be composed using large contiguous chunks of data from the database are considered very likely, whereas regions in the observed data which cannot be composed from the database (or can be composed, but only using small fragmented pieces) are regarded as unlikely/suspicious. The problem is posed as an inference process in a probabilistic graphical model. We show applications of this approach to identifying saliency in images and video, and for suspicious behavior recognition.},
author = {Boiman, Oren and Irani, Michal},
booktitle = {ICCV},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Boiman, Irani - 2005 - Detecting Irregularities in Images and in Video.pdf:pdf},
pages = {462--469},
publisher = {IEEE},
title = {{Detecting Irregularities in Images and in Video}},
volume = {1},
year = {2005}
}
@book{Bishop2006,
author = {Bishop, Christopher M},
publisher = {Springer-Verlag New York, Inc.},
title = {{Pattern Recognition and Machine Learning}},
year = {2006}
}
@inproceedings{Lazebnik2006,
author = {Lazebnik, Svetlana and Schmid, Cordelia and Ponce, Jean},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lazebnik, Schmid, Ponce - 2006 - Beyond Bags of Features Spatial Pyramid Matching for Recognizing Natural Scene Categories.pdf:pdf},
pages = {2169--2178},
publisher = {IEEE},
title = {{Beyond Bags of Features: Spatial Pyramid Matching for Recognizing Natural Scene Categories}},
volume = {2},
year = {2006}
}
@inproceedings{Ren2008,
author = {Ren, Xiaofeng},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ren - 2008 - Finding people in archive films through tracking.pdf:pdf},
month = jun,
pages = {1--8},
publisher = {IEEE},
title = {{Finding people in archive films through tracking}},
volume = {2},
year = {2008}
}
@inproceedings{Escorcia2012,
author = {Escorcia, Victor and Davila, Maria A. and Golparvar-Fard, Mani and Niebles, Juan Carlos},
booktitle = {Construction Research Congress},
title = {Automated Vision-based Recognition of Construction Worker Actions for Building Interior Construction Operations Using {RGBD} Cameras},
year = {2012}
}
@inproceedings{Andriluka2009,
author = {Andriluka, Mykhaylo and Roth, Stefan and Schiele, Bernt},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Andriluka, Roth, Schiele - 2009 - Pictorial structures revisited People detection and articulated pose estimation.pdf:pdf},
pages = {1014--1021},
publisher = {IEEE},
title = {{Pictorial structures revisited: People detection and articulated pose estimation}},
year = {2009}
}
@inproceedings{HanICCV2009,
author = {Han, Dong and Bo, Liefeng and Sminchisescu, Cristian},
booktitle = {ICCV},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Han, Bo, Sminchisescu - 2009 - Selection and Context for Action Recognition.pdf:pdf},
title = {{Selection and Context for Action Recognition}},
year = {2009}
}
@inproceedings{Wang2009a,
author = {Wang, Heng and Ullah, Muhammad Muneeb and Klaser, Alexander and Laptev, Ivan and Schmid, Cordelia},
booktitle = {BMVC},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2009 - Evaluation of local spatio-temporal features for action recognition.pdf:pdf},
title = {{Evaluation of local spatio-temporal features for action recognition}},
year = {2009}
}
@inproceedings{Dalal2006,
author = {Dalal, Navneet and Triggs, Bill and Schmid, Cordelia},
booktitle = {ECCV},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dalal, Triggs, Schmid - 2006 - Human Detection Using Oriented Histograms of Flow and Appearance.pdf:pdf},
pages = {428--441},
title = {{Human Detection Using Oriented Histograms of Flow and Appearance}},
year = {2006}
}
@inproceedings{Laptev2008a,
author = {Laptev, Ivan and Marszalek, Marcin and Schmid, Cordelia and Rozenfeld, Benjamin},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Laptev et al. - 2008 - Learning realistic human actions from movies.pdf:pdf},
month = jun,
pages = {1--8},
publisher = {IEEE},
title = {{Learning realistic human actions from movies}},
year = {2008}
}
@inproceedings{Gilbert2009,
author = {Gilbert, Andrew and Illingworth, John and Bowden, Richard},
booktitle = {ICCV},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gilbert, Illingworth, Bowden - 2009 - Fast Realistic Multi-Action Recognition using Mined Dense Spatio-temporal.pdf:pdf},
title = {{Fast Realistic Multi-Action Recognition using Mined Dense Spatio-temporal}},
year = {2009}
}
@inproceedings{Rodriguez2008,
author = {Rodriguez, Mikel D. and Ahmed, Javed and Shah, Mubarak},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rodriguez, Ahmed, Shah - 2008 - Action MACH A Spatio-temporal Maximum Average Correlation Height Filter for Action Recognition.pdf:pdf},
month = jun,
pages = {1--8},
publisher = {IEEE},
title = {{Action MACH a spatio-temporal Maximum Average Correlation Height filter for action recognition}},
year = {2008}
}
@inproceedings{Duchenne2009,
author = {Duchenne, Olivier and Laptev, Ivan and Sivic, Josef and Bach, Francis and Ponce, Jean},
booktitle = {ICCV},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Duchenne et al. - 2009 - Automatic Annotation of Human Actions in Video.pdf:pdf},
number = {Section 3},
title = {{Automatic Annotation of Human Actions in Video}},
year = {2009}
}
@inproceedings{Pirsiavash2009,
author = {Pirsiavash, Hamed and Ramanan, Deva and Fowlkes, Charless},
booktitle = {NIPS},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pirsiavash, Ramanan, Fowlkes - 2009 - Bilinear classifiers for visual recognition.pdf:pdf},
pages = {1--9},
title = {{Bilinear classifiers for visual recognition}},
year = {2009}
}
@inproceedings{Ramanan2007a,
author = {Ramanan, Deva},
booktitle = {NIPS},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ramanan - 2006 - Learning to Parse Images of Articulated Objects.pdf:pdf},
title = {{Learning to parse images of articulated bodies}},
year = {2007}
}
@inproceedings{Ke2005,
author = {Ke, Yan and Sukthankar, Rahul and Hebert, Martial},
booktitle = {ICCV},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ke, Sukthankar, Hebert - 2005 - Efficient Visual Event Detection Using Volumetric Features.pdf:pdf},
pages = {166--173},
publisher = {IEEE},
title = {{Efficient Visual Event Detection Using Volumetric Features}},
volume = {1},
year = {2005}
}
@inproceedings{Wang2008b,
author = {Wang, Yang and Mori, Greg},
booktitle = {NIPS},
file = {::},
title = {{Learning a Discriminative Hidden Part Model for Human Action Recognition}},
year = {2008}
}
@inproceedings{Sun2009,
annote = {JCN: This paper presents a method for action recognition based on local feature trajectories.},
author = {Sun, Ju and Wu, Xiao and Yan, Shuicheng and Cheong, Loong-Fah and Chua, Tat-Seng and Li, Jintao},
booktitle = {CVPR},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sun et al. - 2009 - Hierarchical spatio-temporal context modeling for action recognition.pdf:pdf},
month = jun,
pages = {2004--2011},
publisher = {IEEE},
title = {{Hierarchical spatio-temporal context modeling for action recognition}},
year = {2009}
}
@article{Ali2007,
abstract = {PDF},
author = {Ali, Saad and Basharat, Arslan and Shah, Mubarak},
journal = {IEEE 11th International Conference on Computer Vision (2007)},
number = {C},
pages = {1--8},
pmid = {3099496670667750897},
publisher = {Ieee},
title = {{Chaotic Invariants for Human Action Recognition}},
volume = {2},
year = {2007}
}
@article{Muller2005,
abstract = {The reuse of human motion capture data to create new, realistic motions by applying morphing and blending techniques has become an important issue in computer animation. This requires the identification and extraction of logically related motions scattered within some data set. Such content-based retrieval of motion capture data, which is the topic of this paper, constitutes a difficult and time-consuming problem due to significant spatio-temporal variations between logically related motions. In our approach, we introduce various kinds of qualitative features describing geometric relations between specified body points of a pose and show how these features induce a time segmentation of motion capture data streams. By incorporating spatio-temporal invariance into the geometric features and adaptive segments, we are able to adopt efficient indexing methods allowing for flexible and efficient content-based retrieval and browsing in huge motion capture databases. Furthermore, we obtain an efficient preprocessing method substantially accelerating the cost-intensive classical dynamic time warping techniques for the time alignment of logically similar motion data streams. We present experimental results on a test data set of more than one million frames, corresponding to 180 minutes of motion. The linearity of our indexing algorithms guarantees the scalability of our results to much larger data sets.},
author = {M\"{u}ller, Meinard and R\"{o}der, Tido and Clausen, Michael},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/M\"{u}ller, R\"{o}der, Clausen - 2005 - Efficient content-based retrieval of motion capture data(2).pdf:pdf},
journal = {ACM Transactions on Graphics},
keywords = {adaptation existing motion,adaptive segmen,bruderlin williams 1995,data,geometric feature,indexing,motion capture,retrieval,tation,techniques modification,time alignment,various editing morphing},
number = {3},
pages = {677},
publisher = {ACM},
title = {{Efficient content-based retrieval of motion capture data}},
volume = {24},
year = {2005}
}
@article{Ikizler2009,
author = {Duygulu, P?nar and Ikizler, Nazli},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Duygulu, Ikizler - 2009 - Histogram of oriented rectangles A new pose descriptor for human action recognition.pdf:pdf},
journal = {Image and Vision Computing},
number = {10},
pages = {1515--1526},
publisher = {Elsevier},
title = {{Histogram of oriented rectangles: A new pose descriptor for human action recognition}},
volume = {27},
year = {2009}
}
@phdthesis{Fanti2008,
author = {Fanti, Claudio},
title = {{Towards Automatic Discovery of Human Movemes}},
year = {2008}
}
@article{Campbell1995,
author = {Campbell, L.W. and a.F. Bobick},
file = {::},
journal = {Proceedings of IEEE International Conference on Computer Vision},
pages = {624--630},
publisher = {IEEE Comput. Soc. Press},
title = {{Recognition of human body motion using phase space constraints}},
year = {1995}
}
@article{jiang10,
author = {Jiang, W and Zicheng, L and Ying, W and Junsong, Y},
journal = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
title = {{Mining Actionlet Ensemble for Action Recognition with Depth Cameras}},
year = {2012}
}
@inproceedings{HatunK.;Duygulu2008,
abstract = {We propose a method for recognizing human actions in videos. Inspired from the recent bag-of-words approaches, we represent actions as documents consisting of words, where a word refers to the pose in a frame. Histogram of oriented gradients (HOG) features are used to describe poses, which are then vector quantized to obtain pose-words. As an alternative to bag-of-words approaches, that only represent actions as a collection of words by discarding the temporal characteristics of actions, we represent videos as ordered sequence of pose-words, that is as pose sentences. Then, string matching techniques are exploited to find the similarity of two action sequences. In the experiments, performed on data set of Blank et al., 92\% performance is obtained.},
author = {{Hatun, K.; Duygulu}, P.},
booktitle = {19th International Conference on Pattern Recognition, 2008. ICPR 2008},
keywords = {Clustering algorithms,Data mining,Feature extraction,Histograms,Humans,Layout,Spatiotemporal phenomena,Text recognition,Vector quantization,Videos},
title = {{Pose Sentences: A new representation for action recognition using sequence of pose words}},
year = {2008}
}
@article{Fanti2005a,
abstract = {Probabilistic models have been previously shown to be ef?cient and effective for modeling and recognition of human motion. In particular we focus on methods which represent the human motion model as a triangulated graph. Previous approaches learned models based just on positions and velocities of the body parts while ignoring their appearance. Moreover, a heuristic approach was commonly used to obtain translation invariance. In this paper we suggest an improved approach for learning such models and using them for human motion recognition. The suggested approach combines multiple cues, i.e., positions, velocities and appearance into both the learning and detection phases. Furthermore, we introduce global variables in the model, which can represent global properties such as translation, scale or view-point. The model is learned in an unsupervised manner from unlabelled data. We show that the suggested hybrid probabilistic model (which combines global variables, like translation, with local variables, like relative positions and appearances of body parts), leads to: (i) faster convergence of learning phase, (ii) robustness to occlusions, and, (iii) higher recognition rate.},
author = {Fanti, C. and Zelnik-Manor, L.},
journal = {Proceedings of the 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)},
pages = {1166--1173},
publisher = {Ieee},
title = {{Hybrid models for human motion recognition}},
volume = {1},
year = {2005}
}
@misc{Ni2011,
abstract = {In this paper, we present a home-monitoring oriented human activity recognition benchmark database, based on the combination of a color video camera and a depth sensor. Our contributions are two-fold: 1) We have created a publicly releasable human activity video database (i.e., named as RGBD-HuDaAct), which contains synchronized color-depth video streams, for the task of human daily activity recognition. This database aims at encouraging more research efforts on human activity recognition based on multi-modality sensor combination (e.g., color plus depth). 2) Two multi-modality fusion schemes, which naturally combine color and depth information, have been developed from two state-of-the-art feature representation methods for action recognition, i.e., spatio-temporal interest points (STIPs) and motion history images (MHIs). These depth-extended feature representation methods are evaluated comprehensively and superior recognition performances over their uni-modality (e.g., color only) counterparts are demonstrated.},
author = {Ni, Bingbing and Wang, Gang and Moulin, Pierre},
booktitle = {2011 IEEE International Conference on Computer Vision Workshops ICCV Workshops},
file = {::},
institution = {Advanced Digital Sciences Center, Singapore 138632},
pages = {1147--1153},
publisher = {IEEE},
title = {{RGBD-HuDaAct: A color-depth video database for human daily activity recognition}},
year = {2011}
}
@article{Thurau2008a,
author = {Thurau, Christian and Hlav\'{a}c, V},
journal = {LNCS},
pages = {169--192},
title = {{Recognizing Human Actions by Their Pose}},
year = {2008}
}
@article{Chen2010,
abstract = {Estimating 3D pose similarity is a fundamental problem on 3D motion data. Most previous work calculates \$L2\$-like distance of joint orientations or coordinates, which does not sufficiently reflect the pose similarity of human perception. In this paper we present a new pose distance metric. First, we propose a new rich pose feature set called $\backslash$emph\{Geometric Pose Descriptor\} ($\backslash$emph\{GPD\}). GPD is more effective in encoding pose similarity by utilizing features on geometric relations among body parts, as well as temporal information such as velocities and accelerations. Based on GPD, we propose a semi-supervised distance metric learning algorithm called $\backslash$emph\{Regularized Distance Metric Learning with Sparse Representation\} ($\backslash$emph\{RDSR\}), which integrates information from both unsupervised data relationship and labels. We apply the proposed pose distance metric to applications of motion transition decision and content based pose retrieval. Quantitative evaluations demonstrate that our method achieves better results with only a small amount of human labels, showing that the proposed pose distance metric is a promising building block for various 3D motion related applications.},
author = {Chen, Cheng and Zhuang, Yueting and Nie, Feiping and Yang, Yi and Wu, Fei and Xiao, Jun},
journal = {IEEE transactions on visualization and computer graphics},
month = dec,
number = {1},
pmid = {21173458},
title = {{Learning a 3D Human Pose Distance Metric from Geometric Pose Descriptor.}},
volume = {6},
year = {2010}
}
@article{Torre2009,
author = {Torre, Fernando De},
editor = {Bengio, Y and Schuurmans, D and Lafferty, J and Williams, C K I and Culotta, A},
journal = {Energy},
number = {20},
pages = {1--9},
title = {{Canonical Time Warping for Alignment of Human Behavior}},
volume = {72},
year = {2009}
}
@inproceedings{Escorcia2012a,
author = {Escorcia, Victor and Davila, Maria A and Golparvar-Fard, Mani and Niebles, Juan Carlos},
booktitle = {Proceedings of Construction Research Congress},
title = {{No Title}},
year = {2012}
}
@article{jiang10,
author = {Jiang, W and Zicheng, L and Ying, W and Junsong, Y},
journal = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
title = {{Mining Actionlet Ensemble for Action Recognition with Depth Cameras}},
year = {2012}
}
@article{Niebles,
author = {Niebles, Juan Carlos and Han, Bohyung and Ferencz, Andras and Fei-fei, Li},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Niebles et al. - 2008 - Extracting Moving People from Internet Videos(2).pdf:pdf},
pages = {1--14},
title = {{Extracting Moving People from Internet Videos}}
}
@article{Laptev2008b,
author = {Laptev, Ivan and Schmid, Cordelia and Rozenfeld, Benjamin},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Laptev, Schmid, Rozenfeld - 2008 - Learning realistic human actions from movies.pdf:pdf},
journal = {CVPR 08},
title = {{Learning realistic human actions from movies}},
year = {2008}
}
@article{Russakovsky2010,
author = {Russakovsky, Olga and Fei-fei, Li},
file = {::},
journal = {Proceedings of the 12th European Conference of Computer Vision (ECCV), 1st International Workshop on Parts and Attributes.},
pages = {1--14},
title = {{Attribute learning in large-scale datasets}},
year = {2010}
}
@inproceedings{Lee2011a,
author = {Lee, Yong Jae and Kim, Jaechul and Grauman, Kristen},
booktitle = {2011 International Conference on Computer Vision},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lee, Kim, Grauman - 2011 - Key-segments for video object segmentation.pdf:pdf},
month = nov,
pages = {1995--2002},
publisher = {IEEE},
title = {{Key-segments for video object segmentation}},
year = {2011}
}
@article{Vondrick,
author = {Vondrick, Carl and Ramanan, Deva and Patterson, Donald},
file = {::},
title = {{Efficiently Scaling Up Video Annotation with Crowdsourced Marketplaces}}
}
@article{J.DengW.DongR.SocherL.-J.Li2009,
author = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
file = {::},
journal = {2009 IEEE Conference on Computer Vision and Pattern Recognition},
month = jun,
pages = {248--255},
publisher = {Ieee},
title = {{ImageNet: A large-scale hierarchical image database}},
year = {2009}
}
@article{Yuen,
author = {Yuen, Jenny and Russell, Bryan and Liu, Ce and Torralba, Antonio},
file = {:home/jniebles/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yuen et al. - 2009 - LabelMe video Building a Video Database with Human Annotations(2).pdf:pdf},
journal = {Event (London)},
pages = {1--8},
title = {{LabelMe video: Building a Video Database with Human Annotations}}
}
@article{Bourdev2010,
author = {Bourdev, Lubomir and Maji, Subhransu and Brox, Thomas and Malik, Jitendra},
chapter = {13},
editor = {Daniilidis, Kostas and Maragos, Petros and Paragios, Nikos},
file = {::},
journal = {European Conference on Computer Vision (ECCV)},
pages = {1--14},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
title = {{Detecting People Using Mutually Consistent Poselet Activations}},
volume = {6316},
year = {2010}
}
@article{Gupta2009b,
abstract = {Interpretation of images and videos containing humans interacting with different objects is a daunting task. It involves understanding scene/event, analyzing human movements, recognizing manipulable objects, and observing the effect of the human movement on those objects. While each of these perceptual tasks can be conducted independently, recognition rate improves when interactions between them are considered. Motivated by psychological studies of human perception, we present a Bayesian approach which integrates various perceptual tasks involved in understanding human-object interactions. Previous approaches to object and action recognition rely on static shape/appearance feature matching and motion analysis, respectively. Our approach goes beyond these traditional approaches and applies spatial and functional constraints on each of the perceptual elements for coherent semantic interpretation. Such constraints allow us to recognize objects and actions when the appearances are not discriminative enough. We also demonstrate the use of such constraints in recognition of actions from static images without using any motion information.},
author = {Gupta, Abhinav and Kembhavi, Aniruddha and Davis, L.S.},
file = {::},
journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
keywords = {Algorithms,Automated,Automated: methods,Bayes Theorem,Biological,Computer-Assisted,Computer-Assisted: methods,Human Activities,Humans,Image Processing,Models,Movement,Movement: physiology,Pattern Recognition,Recognition (Psychology),Video Recording},
month = oct,
number = {10},
pages = {1775--1789},
pmid = {19696449},
publisher = {IEEE},
title = {{Observing human-object interactions: Using spatial and functional compatibility for recognition}},
volume = {31},
year = {2009}
}
@article{Prest2011,
abstract = {We introduce a weakly supervised approach for learning human actions modeled as interactions between humans and objects. Our approach is human-centric: we first localize a human in the image and then determine the object relevant for the action and its spatial relation with the human. The model is learned automatically from a set of still images annotated only with the action label. Our approach relies on a human detector to initialize the model learning. For robustness to various degrees of visibility, we build a detector that learns to combine a set of existing part detectors. Starting from humans detected in a set of images depicting the action, our approach determines the action object and its spatial relation to the human. Its final output is a probabilistic model of the human-object interaction, i.e. the spatial relation between the human and the object. We present an extensive experimental evaluation on the sports action dataset from Gupta et al., the PASCAL Action 2010 dataset, and a new human-object interaction dataset.},
author = {Prest, Alessandro and Schmid, Cordelia and Ferrari, Vittorio},
file = {::},
journal = {IEEE transactions on pattern analysis and machine intelligence},
month = jul,
pages = {1--14},
pmid = {21808083},
title = {{Weakly Supervised Learning of Interactions between Humans and Objects.}},
year = {2011}
}
@article{Delaitre2009,
author = {Delaitre, Vincent and Laptev, Ivan},
file = {::},
journal = {BMVC 2010 - British Machine Vision Conference},
pages = {97.1--97.11},
publisher = {British Machine Vision Association},
title = {{Recognizing human actions in still images: a study of bag-of-features and part-based representations}},
year = {2010}
}
@article{Sadeghi2011,
author = {Sadeghi, Mohammad Amin and Farhadi, Ali},
file = {::},
journal = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = jun,
pages = {1745--1752},
publisher = {Ieee},
title = {{Recognition using visual phrases}},
year = {2011}
}
@article{Yao2011a,
author = {Yao, Bangpeng and Khosla, Aditya and Fei-Fei, Li},
file = {::},
journal = {International Conference on Machine Learning (ICML)},
title = {{Classifying Actions and Measuring Action Similarity by Modeling the Mutual Context of Objects and Human Poses}},
year = {2011}
}
@article{Felzenszwalb2010a,
abstract = {We describe an object detection system based on mixtures of multiscale deformable part models. Our system is able to represent highly variable object classes and achieves state-of-the-art results in the PASCAL object detection challenges. While deformable part models have become quite popular, their value had not been demonstrated on difficult benchmarks such as the PASCAL data sets. Our system relies on new methods for discriminative training with partially labeled data. We combine a margin-sensitive approach for data-mining hard negative examples with a formalism we call latent SVM. A latent SVM is a reformulation of MI-SVM in terms of latent variables. A latent SVM is semiconvex, and the training problem becomes convex once latent information is specified for the positive examples. This leads to an iterative training algorithm that alternates between fixing latent values for positive examples and optimizing the latent SVM objective function.},
author = {Felzenszwalb, Pedro F and Girshick, Ross B and McAllester, David and Ramanan, Deva},
institution = {Department of Computer Science, University of Chicago, 1100 E. 58th Street, Chicago, IL 60637, USA. pff@cs.uchicago.edu},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {algorithms,artificial intelligence,automated,automated methods,computer assisted,computer assisted methods,discriminant analysis,image enhancement,image enhancement methods,image interpretation,imaging,pattern recognition,reproducibility results,sensitivity specificity,three dimensional,three dimensional methods},
number = {9},
pages = {1627--1645},
pmid = {20634557},
publisher = {IEEE},
title = {{Object detection with discriminatively trained part-based models.}},
volume = {32},
year = {2010}
}
@article{Ryoo2007,
abstract = {The paper presents a system that recognizes humans interacting with objects. We delineate a new framework that integrates object recognition, motion estimation, and semantic-level recognition for the reliable recognition of hierarchical human-object interactions. The framework is designed to integrate recognition decisions made by each component, and to probabilistically compensate for the failure of the components with the use of the decisions made by the other components. As a result, human-object interactions in an airport-like environment, such as a person carrying a baggage, a person leaving his/her baggage, or a person snatching another's baggage, are recognized. The experimental results show that not only the performance of the final activity recognition is superior to that of previous approaches, but also the accuracy of the object recognition and the motion estimation increases using feedback from the semantic layer. Several real examples illustrate the superior performance in recognition and semantic description of occurring events.},
author = {Ryoo, M S and Aggarwal, J K},
journal = {IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},
pages = {1--8},
publisher = {IEEE},
title = {{Hierarchical Recognition of Human Activities Interacting with Objects}},
year = {2007}
}
@inproceedings{E.BermejoO.DenizG.Bueno2011,
annote = {Detection of violent actions.
Useful in prisions, sychiatric or elderly centers.
        
Action recognition based on bags-of-words framework with 2 descriptors: space-time interes points (STIPS) and Motion SIFT (MoSIFT).
        
      },
author = {{E. Bermejo, O. Deniz, G. Bueno}, R. Sukthankar.},
booktitle = {Proceedings of Computer Analysis of Images and Patterns, 2011.},
file = {::},
title = {{Violence Detection in Video using Computer Vision Techniques}},
year = {2011}
}
@inproceedings{Syngelakis2011,
author = {Syngelakis, Emmanouil and Collomosse, John},
booktitle = {1st Intl. Symposium on Ambient Technologies (AMBIENT)},
title = {{A Bag of Features Approach to Ambient Fall Detection for Domestic Elder-care}},
year = {2011}
}
@inproceedings{Zhao2011,
author = {Zhao, Bin and Fei-Fei, Li and Xing, Eric P.},
booktitle = {CVPR},
month = jun,
pages = {3313--3320},
publisher = {IEEE},
title = {{Online detection of unusual events in videos via dynamic sparse coding}},
year = {2011}
}
@article{Wu2011,
author = {Wu, Handong and Oreifej, Omar and {Mubarak Shah}},
journal = {ICCV},
title = {Action Recognition in Videos Acquired by a Moving Camera Using Motion Decomposition of Lagrangian Particle Trajectories},
year = {2011}
}
@article{McKenna2005,
annote = {Detection of unusual inactivities.
This work use wide-angle monocular cameras, to avoid occlusions with other objects, at home environment.
        
Trajectories based on tracks of ellipses. The tracking was performed with particle filtering, Iterated likelihood weighting (ILW).
5D elipse parameter, for tracked person in each sequence. Person Speed, ellipse centre trajectories, pose information.
        
Spatial Context
Gauusian mixture models - GMM
      },
author = {McKenna, Stephen J. and Charif, Hammadi Nait},
file = {::},
journal = {Pattern Analysis and Applications},
month = may,
number = {4},
pages = {386--401},
title = {{Summarising contextual activity and detecting unusual inactivity in a supportive home environment}},
volume = {7},
year = {2005}
}
@misc{SurviCam2012,
keywords = {elderly people},
mendeley-tags = {elderly people},
title = {{Elderly People Video Surveillance By SurviCam}},
year = {2012}
}
@article{Reyes-Ortiz2005,
abstract = {To estimate the prevalence of and risk factors for falls among community-dwelling elders in Latin America and the Caribbean and among elderly Mexican-Americans in the southwestern United States.},
author = {Reyes-Ortiz, Carlos A and {Al Snih}, Soham and Markides, Kyriakos S},
journal = {Revista panamericana de salud p\'{u}blica},
keywords = {Accidental Falls,Accidental Falls: statistics \& numerical data,Aged,Caribbean Region,Caribbean Region: epidemiology,Female,Humans,Latin America,Latin America: epidemiology,Male,Mexican Americans,Mexican Americans: statistics \& numerical data,Prevalence,United States,United States: epidemiology},
number = {5-6},
pages = {362--9},
pmid = {16053646},
title = {{Falls among elderly persons in Latin America and the Caribbean and among elderly Mexican-Americans}},
volume = {17},
year = {2005}
}
@techreport{Tremblay2012,
author = {Tremblay, K.R. and Barber, C.E.},
institution = {Colorado State University},
keywords = {elder care},
title = {{Preventing Falls in the Elderly}},
year = {2012}
}
@inproceedings{Foroughi2008,
annote = {Video surveillance at home scenarios for elderly  care. Aplication to detect different activities, focus on falls detection. 
Features of boundary and motion to detect postures-based events.
        
1.background segmentation
2.features: Ellipses like boundary delimiter (orientation and ratio standard deviation of the ellipses. Projection histograms of segmented silhouettes.Temporal changes of head position.
3.MLP neuronal network to classification problem.},
author = {Foroughi, Homa and Aski, Baharak Shakeri and Pourreza, Hamidreza},
booktitle = {2008 11th International Conference on Computer and Information Technology},
month = dec,
pages = {219--224},
publisher = {IEEE},
title = {{Intelligent video surveillance for monitoring fall detection of elderly in home environments}},
year = {2008}
}
@techreport{WorldHealthOrganization2007,
author = {{World Health Organization}},
title = {{WHO Global report on falls Prevention in older Age}},
year = {2007}
}
@article{Rougier2006a,
abstract = {Faced with the growing population of seniors, Western societies need to think about new technologies to ensure the safety of elderly people at home. Computer vision provides a good solution for healthcare systems because it allows a specific analysis of people behavior. Moreover, a system based on video surveillance is particularly well adapted to detect falls. We present a new method to detect falls using a single camera. Our approach is based on the 3D trajectory of the head, which allows us to distinguish falls from normal activities using 3D velocities.},
annote = {Detects falls using a single camera.
Aproach based on 3D trajectory of the head. Considering 3D velocities.
The system active an alert when is detected a dangeorus situation (when a perosn is falling).
        
1-Tracking the head of the person. This option is by the head move considerably during a fall. Ellypse around the head.  
Detects the head with POSIT algorithm.
        
2-Extraction 3D head trajectory. 
3D refers to XY position and time.
Tracking with particle filters "Condensation algorithm" (Conditional density propagation)
        
3-Falls detection based on velocity characteristics.
Horizontal and vertical velocity.},
author = {Rougier, Caroline and Meunier, Jean and St-Arnaud, Alain and Rousseau, Jacqueline},
file = {::},
journal = {Conference proceedings : ... Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Conference},
keywords = {Accidental Falls,Accidents,Aged,Automated,Computer-Assisted,Computers,Equipment Design,Head,Head: pathology,Home,Home Care Services,Humans,Image Interpretation,Imaging,Pattern Recognition,Software,Three-Dimensional},
month = jan,
pages = {6384--7},
pmid = {17947190},
title = {{Monocular 3D head tracking to detect falls of elderly people.}},
volume = {1},
year = {2006}
}
@techreport{Jackson2009,
author = {Jackson, R. and Strauss, R. and Howe, N.},
institution = {Center for Strategic and International Studies},
title = {{Latin America’s AGING CHALLENGE}},
year = {2009}
}
@inproceedings{Turjo2005,
annote = {Intelligent system to detect falls in video surveillance. The authors develop an interface to proof the method in real-time videoS, work at indoor environments.
        
1. Vision component detects and track moving people.
Detect and segment moving people using a self-learned background model. 
The feature is aspect ratio (height over width).
        
2. Event-inference module that identify people falling from sequences of peoples.
        
      },
author = {Turjo, Mukherjee and Wong, Mun-Fei and Wang, Mengdi and Tan, Yap-Peng},
booktitle = {2005 5th International Conference on Information Communications \& Signal Processing},
file = {::},
pages = {1590--1594},
publisher = {IEEE},
title = {{Fall Incidents Detection for Intelligent Video Surveillance}},
year = {2005}
}
@unpublished{Bloom2011,
author = {Bloom, D. and Canning, D. and G\"{u}nther, F.},
institution = {HARVARD CENTER FOR POPULATION AND DEVELOPMENT STUDIES},
title = {{Implications of Population Aging for Economic Growth}},
year = {2011}
}
@article{NiScanaill2006,
abstract = {Rapid technological advances have prompted the development of a wide range of telemonitoring systems to enable the prevention, early diagnosis and management, of chronic conditions. Remote monitoring can reduce the amount of recurring admissions to hospital, facilitate more efficient clinical visits with objective results, and may reduce the length of a hospital stay for individuals who are living at home. Telemonitoring can also be applied on a long-term basis to elderly persons to detect gradual deterioration in their health status, which may imply a reduction in their ability to live independently. Mobility is a good indicator of health status and thus by monitoring mobility, clinicians may assess the health status of elderly persons. This article reviews the architecture of health smart home, wearable, and combination systems for the remote monitoring of the mobility of elderly persons as a mechanism of assessing the health status of elderly persons while in their own living environment.},
author = {{N\'{\i} Scanaill}, Cliodhna and Carew, Sheila and Barralon, Pierre and Noury, Norbert and Lyons, Declan and Lyons, Gerard M},
journal = {Annals of biomedical engineering},
keywords = {80 and over,Aged,Chronic Disease,Female,Humans,Male,Monitoring,Motor Activity,Physiologic,Physiologic: instrumentation,Physiologic: methods,Telemedicine,Telemedicine: instrumentation,Telemedicine: methods},
month = apr,
number = {4},
pages = {547--63},
pmid = {16550450},
title = {{A review of approaches to mobility telemonitoring of the elderly in their living environment.}},
volume = {34},
year = {2006}
}
@article{Sixsmith2004,
author = {Sixsmith, A and Johnson, N},
journal = {Pervasive Computing, IEEE},
keywords = {SIMBAD project,Smart Inactivity Monitor using Arra},
number = {2},
pages = {42--47},
title = {{A smart sensor to detect the falls of the elderly}},
volume = {3},
year = {2004}
}
@inproceedings{Grauman2009,
author = {Kim, Jaechul and Grauman, Kristen},
booktitle = {CVPR},
month = jun,
pages = {2921--2928},
publisher = {IEEE},
title = {{Observe locally, infer globally: A space-time MRF for detecting abnormal activities with incremental updates}},
year = {2009}
}
@article{Boiman2007,
author = {Boiman, Oren and Irani, Michal},
journal = {International Journal of Computer Vision},
month = jan,
number = {1},
pages = {17--31},
title = {{Detecting Irregularities in Images and in Video}},
volume = {74},
year = {2007}
}
@inproceedings{WangCVPR2011,
author = {Wang, Heng and Klaser, A and Schmid, Cordelia and Liu, Cheng-Lin},
booktitle = {CVPR},
file = {::},
keywords = {KLT tracker,SIFT descriptor matching,action recogn},
title = {Action recognition by dense trajectories},
year = {2011}
}

@article{Miskelly2001,
annote = {That is a document about the tools that support the care of elderly peoplen in institutions and at home.
        
This assistive technological equipment are among others, electronic sensors, remote health monitoring, equipmet such as fall detectors, door monitors, bed alerts, pressure mats, smoke and heat alarms and video-monitoring.
        
This document consider the video-monitoring like an expensive equipment with respect to sensors and alarms.},
author = {Miskelly, F. G.},
file = {::},
journal = {Age and Ageing},
month = nov,
number = {6},
pages = {455--458},
title = {{Assistive technology in elderly care}},
volume = {30},
year = {2001}
}
@inproceedings{LanIWSGA2010,
annote = {Contextual representations to action retrieval. Features spatio-temporal. Bags-of-words representations.
        
1.new feature representation Action context (AC) descriptor: Information about action of an individual and behavior people nearby.
2. retrieval/ranking task. Different approach to the common classification task. Action retrieval using Rank-SVM.
        
Focus on people falling, elderly specially, because it's important to doctors, nurse, clinician to develop strategies for prevention.
Label: people falling "very relevant", people aid other people that falls "relevant", other people "irrelevant".
        
        
Dataset (nursing home data) recorded by medical collaborators, with a fish eye camera. 10 videos (3mins) without fallas and 10 videos with falls. Actions: walking,  sitting,standing, falling, other people help fallen person tu stand up, etc.},
author = {Lan, Tian and Wang, Yang and Mori, Greg and Robinovitch, Stephen},
booktitle = {International Workshop on Sign Gesture Activity},
file = {::},
title = {{Retrieving Actions in Group Context}},
year = {2010}
}
@book{Downton1993,
address = {London},
author = {Downton, Joanna H.},
publisher = {Edward Arnold},
title = {{Falls in the Elderly}},
year = {1993}
}
@inproceedings{Visontai,
author = {Zhong, Hua and Shi, Jianbo and Visontai, Mirko},
booktitle = {CVPR},
pages = {819--826},
publisher = {IEEE},
title = {{Detecting unusual activity in video}},
volume = {2},
year = {2004}
}
@inproceedings{Miaou2006,
annote = {They capture the video information around 360° (omni-cameras). The system include personal information such as height, weight and health history, to adjust the sensitivity dependent of everyone to reduce unnecessary alarms or putt more attention on elderly with critical health conditions.
        
*The system flow chart highlighted in the paper explain the algorithm to detect falls.},
author = {Miaou, Shaou-Gang and Sung, Pei-Hsu and Huang, Chia-Yuan},
booktitle = {1st Transdisciplinary Conference on Distributed Diagnosis and Home Healthcare, 2006. D2H2.},
file = {::},
pages = {39--42},
publisher = {IEEE},
title = {{A Customized Human Fall Detection System Using Omni-Camera Images and Personal Information}},
year = {2006}
}
@inproceedings{Noury2007,
author = {Noury, N and Fleury, A and Rumeau, P and Bourke, A K and Laighin, G O and Rialle, V and Lundy, J E},
booktitle = {Engineering in Medicine and Biology Society, 2007. EMBS 2007. 29th Annual International Conference of the IEEE},
keywords = {automatic early detection,elderly persons,fall det},
pages = {1663--1666},
title = {{Fall detection - Principles and Methods}},
year = {2007}
}
@article{Kasteren2010,
author = {Kasteren, T. L. M. and Englebienne, G. and Kr\"{o}se, B. J. A.},
file = {::},
journal = {Personal and Ubiquitous Computing},
month = feb,
number = {6},
pages = {489--498},
title = {{An activity monitoring system for elderly care using generative and discriminative models}},
volume = {14},
year = {2010}
}
@article{Brown1995,
author = {Brown, Dorothy I.},
journal = {Rehabilitation Nursing},
month = mar,
number = {2},
pages = {84--89},
title = {{Falls in the Elderly Population: A Look at Incidence, Risks, Healthcare Costs, and Preventive Strategies}},
volume = {20},
year = {1995}
}
@article{Rougier2006,
abstract = {Faced with the growing population of seniors, Western societies need to think about new technologies to ensure the safety of elderly people at home. Computer vision provides a good solution for healthcare systems because it allows a specific analysis of people behavior. Moreover, a system based on video surveillance is particularly well adapted to detect falls. We present a new method to detect falls using a single camera. Our approach is based on the 3D trajectory of the head, which allows us to distinguish falls from normal activities using 3D velocities.},
author = {Rougier, Caroline and Meunier, Jean and St-Arnaud, Alain and Rousseau, Jacqueline},
journal = {Conference proceedings : ... Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Conference},
keywords = {Accidental Falls,Accidents,Aged,Automated,Computer-Assisted,Computers,Equipment Design,Head,Head: pathology,Home,Home Care Services,Humans,Image Interpretation,Imaging,Pattern Recognition,Software,Three-Dimensional},
month = jan,
pages = {6384--7},
pmid = {17947190},
title = {{Monocular 3D head tracking to detect falls of elderly people.}},
volume = {1},
year = {2006}
}
@misc{Minesota,
author = {of Minesota, University},
title = {{Unusual Crowd Activity Dataset}},
}
@misc{iWatchLife2012,
keywords = {Elder care,IP security camera,elder care,video security system,webcam security,wireless security camera},
mendeley-tags = {elder care},
title = {{Caring for the Elderly with iWatchLife Smart Video Security System}},
}
@misc{Behave,
title = {{BEHAVE Dataset}},
}
@article{weinland2011survey,
  title={A survey of vision-based methods for action representation, segmentation and recognition},
  author={Weinland, Daniel and Ronfard, Remi and Boyer, Edmond},
  journal={CVIU},
  volume={115},
  number={2},
  pages={224--241},
  year={2011}
}


@article{vishwakarma2013survey,
  title={A survey on activity recognition and behavior understanding in video surveillance},
  author={Vishwakarma, Sarvesh and Agrawal, Anupam},
  journal={The Visual Computer},
  volume={29},
  number={10},
  pages={983--1009},
  year={2013},
  publisher={Springer}
}

@article{aggarwal2014human,
  title={Human activity recognition from {3D} data: A review},
  author={Aggarwal, J. K. and Xia, Lu},
  journal={Pattern Recognition Letters},
  volume = "48",
  pages = "70 - 80",
  year={2014},
  publisher={Elsevier}
}
@article{wan20143d,
  title={{3D SMoSIFT}: three-dimensional sparse motion scale invariant feature transform for activity recognition from {RGB-D} videos},
  author={Wan, Jun and Ruan, Qiuqi and Li, Wei and An, Gaoyun and Zhao, Ruizhen},
  journal={Journal of Electronic Imaging},
  volume={23},
  number={2},
  year={2014}
}
@article{luo2014spatio,
  title={Spatio-temporal feature extraction and representation for {RGB-D} human action recognition},
  author={Luo, Jiajia and Wang, Wei and Qi, Hairong},
  journal={Pattern Recognition Letters},
  volume={50},
  number={1},
  pages={139-148},
  year={2014},
  publisher={Elsevier}
}
@inproceedings{vemulapalli2014human,
  title={Human action recognition by representing {3D} skeletons as points in a {L}smie group},
  author={Vemulapalli, Raviteja and Arrate, Felipe and Chellappa, Rama},
  booktitle={CVPR},
  year={2014}
}
@inproceedings{raptis2013poselet,
  title={Poselet key-framing: A model for human activity recognition},
  author={Raptis, Michalis and Sigal, Leonid},
  booktitle={CVPR},
  year={2013}
}
@inproceedings{chaaraoui2013fusion,
  title={Fusion of Skeletal and Silhouette-based Features for Human Action Recognition with {RGB-D} Devices},
  author={Chaaraoui, Alexandros Andre and Padilla-L{\'o}pez, Jos{\'e} Ram{\'o}n and Fl{\'o}rez-Revuelta, Francisco},
  booktitle={ICCV Workshops},
  year={2013}
}
@inproceedings{zanfir2013moving,
  title={The Moving Pose: An Efficient 3D Kinematics Descriptor for Low-Latency Action Recognition and Detection},
  author={Zanfir, Mihai and Leordeanu, Marius and Sminchisescu, Cristian},
  booktitle={Computer Vision (ICCV), 2013 IEEE International Conference on},
  pages={2752--2759},
  year={2013},
  organization={IEEE}
}

@INPROCEEDINGS{Shahroudy2014, 
author={Shahroudy, A. and Gang Wang and Tian-Tsong Ng}, 
booktitle={ISCCSP}, 
title={Multi-modal feature fusion for action recognition in RGB-D sequences}, 
year={2014}, 
keywords={image fusion;image recognition;image sequences;video signal processing;Microsoft Kinect;RGB videos;RGB-D sequences;action recognition techniques;depth sequences;feature extraction;fuse atomic features;hierarchical bag-of-words feature fusion technique;multimodal feature fusion;multimodal information fusion;multiview structured sparsity learning;skeleton information;Dictionaries;Feature extraction;Fuses;Joints;Vectors;Videos;Action Recognition;Feature Fusion;Kinect;Structured Sparsity}, 
}
@inproceedings{Lan2015,
author={Tian Lan and Yuke Zhu and Amir R. Zamir and Silvio Savarese},
booktitle={ICCV},
year={2015},
title={Action Recognition by Hierarchical Mid-level Action Elements},
}

@inproceedings{maji2011action,
  title={Action recognition from a distributed representation of pose and appearance},
  author={Maji, Subhransu and Bourdev, Lubomir and Malik, Jitendra},
  booktitle={CVPR},
  year={2011},
}
